{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10. Introduction to Artificial Neural Networks\n",
    "\n",
    "Key idea inspired _artificial neural networks_(ANNs): study brain's architecture for inspiration on how to build an intelligent machine.\n",
    "\n",
    "ANNs are the very core of Deep Learning. They are versatile, powerful, and scalable, making them ideal to tackle large and highly complex Machine Learning tasks.\n",
    "\n",
    "### From Biological to Artificial Neurons\n",
    "\n",
    "ANNS first introduced as _propositional logic_ in 1943 by Warren McCulloch and Walter Pitts. \n",
    "\n",
    "In the early 1980s there was a revival of interest in ANNs as new network architectures were invented and better training techniques were developed. But by the 1990s, powerful alternative Machine Learning techniques such as\n",
    "Support Vector Machines.\n",
    "\n",
    "Reasons to believe this wave of interest in ANNs is different and will have a much more profound impact on our lives:\n",
    " - Huge quantity of data available to train neural networks, and ANNs frequently outperform other ML techniques on very large and complex problems.\n",
    " - Computing power (Moore's Law, GPUs)\n",
    " - The training algorithms have been improved.\n",
    " - Some theoretical limitations of ANNs have turned out to be benign in practice.\n",
    " - ANNs seem to have entered a virtuous circle of funding and progress.\n",
    " \n",
    "#### Biological Neurons\n",
    "\n",
    "Each neuron typically connected to thousands of other neurons. Highly complex computations can be performed by a vast network of fairly simple neurons.\n",
    "\n",
    "<div style=\"width:400 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig10-1.png\" width=400px alt=\"fig10-1\" style=\"padding-bottom:1.0em;padding-top:2.0em;\"></center>_Figure 10-1. Biological neuron_</div>\n",
    "\n",
    "#### Logical Computations with Neurons\n",
    "\n",
    "_Artificial neuron_: one or more binary (on/off) inputs and one binary output. (Such simplified model can build a network of artificial neurons that computes any logical proposition.)\n",
    "\n",
    "#### The perceptron\n",
    "\n",
    "*Perceptron*: one of the simplest ANN architectures, invented in 1957 by Frank Rosenblatt. It is based on a slightly different artificial neuron called a _linear threshold unit_ (LTU): the inputs and output are now numbers (instead of binary on/off values) and each input connection is associated with a weight.\n",
    "\n",
    "<div style=\"width:400 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig10-4.png\" width=400px alt=\"fig10-4\" style=\"padding-bottom:1.0em;padding-top:2.0em;\"></center>_Figure 10-4. Linear shreshold unit_</div>\n",
    "\n",
    "_Common step functions used in Perceptrons_\n",
    "\n",
    "$$heaviside \\ (z) = \\left\\{\\begin{matrix}\n",
    "0 \\ \\ if \\ z<0\n",
    "\\\\ \n",
    "1 \\ \\ if \\ z \\ge 0\n",
    "\\end{matrix}\\right. \\ \\ \\ \\ \\ \\ \\ sgn \\ (z) = \\left\\{\\begin{matrix}\n",
    "-1 \\ \\ if \\ z<0\n",
    "\\\\ \n",
    "0 \\ \\ if \\ z=0\n",
    "\\\\\n",
    "1 \\ \\ if \\ z \\ge 0\n",
    "\\end{matrix}\\right.$$\n",
    "\n",
    "A Perceptron is simply composed of a single layer of LTUs, with each neuron connected to all the inputs.\n",
    "These connections are often represented using special passthrough neurons called _input neurons_: they just\n",
    "output whatever input they are fed. Moreover, an extra bias feature is generally added ($x_0 = 1$). This bias\n",
    "feature is typically represented using a special type of neuron called a _bias neuron_, which just outputs 1\n",
    "all the time.\n",
    "\n",
    "<div style=\"width:400 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig10-5.png\" width=400px alt=\"fig10-5\" style=\"padding-bottom:1.0em;padding-top:2.0em;\"></center>Figure 10-5. Perceptron diagram. This Perceptron can classify instances simultaneously into three different binary classes, which makes it a multioutput\n",
    "classifier.</div>\n",
    "\n",
    "How is a Perceptron trained?\n",
    "\n",
    "Hebb's rule (Hebbian learning): the connection weight between two neurons is increased whenever they have the same\n",
    "output.\n",
    "\n",
    "Perceptrons are trained using a variant of this rule that takes into account the error made by the network; it does not reinforce connections that lead to the wrong output. More specifically, the Perceptron is fed one training instance at a time, and for each instance it makes its predictions. For every output neuron that produced a wrong prediction, it reinforces the connection weights from the inputs that would have contributed to the correct prediction. The rule is shown as\n",
    "\n",
    "*Perceptron learning rule (weight update)*\n",
    "\n",
    "$$ w_{i,j}^{next\\_step} = w_{i,j} + \\eta(\\hat{y}_j - y_j)x_i$$\n",
    "\n",
    "*Perceptron convergence Theorem* if the training instances are linearly separable, this algorithm would converge to a solution. \n",
    "\n",
    "Prefer Logistic Regression over Perceptrons, because instead of outputting a class probability, Perceptrons just make predictions based on a hard threshold.\n",
    "\n",
    "*Multi-Layer Perceptron* (MLP) can eliminate some of the limitations of Perceptrons, while single-layer perceptrons are incapable of solving some trivial problems.\n",
    "\n",
    "#### Multi_layer Perceptron and Backpropagation\n",
    "\n",
    "An MLP is composed of one (passthrough) input layer, one or more layers of LTUs, called _hidden layers_, and one final layer of LTUs called the _output layer_. Every layer except the output layer includes a bias neuron and is fully connected to the next layer. \n",
    "\n",
    "*Deep neural network* (DNN): ANN has two or more hidden layers.\n",
    "\n",
    "<div style=\"width:400 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig10-7.png\" width=400px alt=\"fig10-7\" style=\"padding-bottom:1.0em;padding-top:2.0em;\"></center>*Figure 10-7. Multi-Layer Perceptron*</div>\n",
    "\n",
    "Backpropagation training algorithm, same as Gradient Descent using reverse-mode autodiff: For each training instance the backpropagation algorithm first makes a prediction (forward pass), measures the error, then goes through each layer in reverse to measure the error contribution from each connection (reverse pass), and finally slightly tweaks the connection weights to reduce the error (Gradient Descent step).\n",
    "\n",
    "*Activation (Step) function* with well-defined nonzero derivative everywhere:\n",
    " - *Logistic function*, $\\sigma (z)=1/(1+\\exp(z)) \\ \\ \\in [0,1]$ \n",
    " - _Hyperbolic tangent function_, $\\tanh (z) = 2\\sigma (2z)-1 \\ \\ \\in [-1,1]$, make each layer's output normalized (i.e., centered around 0) at the beginning of training. Speed up convergence.\n",
    " - _ReLU function_, $ReLU(z)=\\max(0,z) \\ \\  \\in [0,\\infty)$, fast to compute gradient.\n",
    " \n",
    "<div style=\"width:400 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig10-8.png\" width=500px alt=\"fig10-8\" style=\"padding-bottom:1.0em;padding-top:2.0em;\"></center>_Figure 10-8. Activation functions ans their derivatives_</div>\n",
    "\n",
    "An MLP is often used for classification, with each output corresponding to a different binary class. When the classes are exclusive, the output layer is typically modified by replacing the individual activation\n",
    "functions by a shared _softmax_ function. The output of each neuron corresponds to the estimated probability of the corresponding class. Note that the signal flows only in one direction (from the inputs to the outputs), so this architecture is an example of a *feedforward neural network* (FNN).\n",
    "\n",
    "<div style=\"width:400 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig10-9.png\" width=400px alt=\"fig10-9\" style=\"padding-bottom:1.0em;padding-top:2.0em;\"></center>_Figure 10-9. A modern MLP (including ReLU and softmax) for classification_</div>\n",
    "\n",
    "<font color=blue>*NOTE*</font>\n",
    ">Biological neurons seem to implement a roughly sigmoid (S-shaped) activation function, so researchers stuck to sigmoid functions for a very long time. But it turns out that the ReLU activation function generally works better in ANNs.\n",
    "\n",
    "### Training an MLP with TensorFlow's High-Level API\n",
    "\n",
    "Trains a DNN for classification with two hidden layers (one with 300 neurons, and the other with 100 neurons) and a softmax output layer with 10 neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpxbj91xes\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpxbj91xes', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f18a0121fd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /home/lei/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/lei/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/lei/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/lei/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/lei/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/adagrad.py:108: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/lei/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpxbj91xes/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.4206889, step = 0\n",
      "INFO:tensorflow:global_step/sec: 376.379\n",
      "INFO:tensorflow:loss = 2.1718338, step = 100 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.153\n",
      "INFO:tensorflow:loss = 1.9351305, step = 200 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.929\n",
      "INFO:tensorflow:loss = 1.80312, step = 300 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.554\n",
      "INFO:tensorflow:loss = 1.6138555, step = 400 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.529\n",
      "INFO:tensorflow:loss = 1.4830735, step = 500 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.209\n",
      "INFO:tensorflow:loss = 1.1872517, step = 600 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.519\n",
      "INFO:tensorflow:loss = 0.80009806, step = 700 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.197\n",
      "INFO:tensorflow:loss = 0.9479822, step = 800 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.668\n",
      "INFO:tensorflow:loss = 0.8881033, step = 900 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.528\n",
      "INFO:tensorflow:loss = 0.7646496, step = 1000 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.843\n",
      "INFO:tensorflow:loss = 0.7547093, step = 1100 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.489\n",
      "INFO:tensorflow:loss = 0.8377722, step = 1200 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.28\n",
      "INFO:tensorflow:loss = 0.69251, step = 1300 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.096\n",
      "INFO:tensorflow:loss = 0.594465, step = 1400 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.938\n",
      "INFO:tensorflow:loss = 0.60421866, step = 1500 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.951\n",
      "INFO:tensorflow:loss = 0.78980654, step = 1600 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.915\n",
      "INFO:tensorflow:loss = 0.72118425, step = 1700 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.321\n",
      "INFO:tensorflow:loss = 0.4877445, step = 1800 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.628\n",
      "INFO:tensorflow:loss = 0.49942273, step = 1900 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.158\n",
      "INFO:tensorflow:loss = 0.6051995, step = 2000 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.983\n",
      "INFO:tensorflow:loss = 0.74372023, step = 2100 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.692\n",
      "INFO:tensorflow:loss = 0.56036043, step = 2200 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.928\n",
      "INFO:tensorflow:loss = 0.35632935, step = 2300 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.136\n",
      "INFO:tensorflow:loss = 0.6485356, step = 2400 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.616\n",
      "INFO:tensorflow:loss = 0.59223, step = 2500 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.607\n",
      "INFO:tensorflow:loss = 0.6084304, step = 2600 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.83\n",
      "INFO:tensorflow:loss = 0.503819, step = 2700 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.603\n",
      "INFO:tensorflow:loss = 0.30937344, step = 2800 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.136\n",
      "INFO:tensorflow:loss = 0.29639506, step = 2900 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.543\n",
      "INFO:tensorflow:loss = 0.42564502, step = 3000 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.679\n",
      "INFO:tensorflow:loss = 0.3313108, step = 3100 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.675\n",
      "INFO:tensorflow:loss = 0.5798658, step = 3200 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.809\n",
      "INFO:tensorflow:loss = 0.41915718, step = 3300 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.039\n",
      "INFO:tensorflow:loss = 0.39371586, step = 3400 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.299\n",
      "INFO:tensorflow:loss = 0.46388748, step = 3500 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.198\n",
      "INFO:tensorflow:loss = 0.46262848, step = 3600 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.889\n",
      "INFO:tensorflow:loss = 0.40964144, step = 3700 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.022\n",
      "INFO:tensorflow:loss = 0.42613357, step = 3800 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.652\n",
      "INFO:tensorflow:loss = 0.23607014, step = 3900 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.098\n",
      "INFO:tensorflow:loss = 0.30303144, step = 4000 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.21\n",
      "INFO:tensorflow:loss = 0.40989795, step = 4100 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.946\n",
      "INFO:tensorflow:loss = 0.33182144, step = 4200 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.297\n",
      "INFO:tensorflow:loss = 0.7650296, step = 4300 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.064\n",
      "INFO:tensorflow:loss = 0.47372454, step = 4400 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.344\n",
      "INFO:tensorflow:loss = 0.40382197, step = 4500 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.846\n",
      "INFO:tensorflow:loss = 0.3759216, step = 4600 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.31678146, step = 4700 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.598\n",
      "INFO:tensorflow:loss = 0.37759888, step = 4800 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.283\n",
      "INFO:tensorflow:loss = 0.371641, step = 4900 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.439\n",
      "INFO:tensorflow:loss = 0.2906327, step = 5000 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.048\n",
      "INFO:tensorflow:loss = 0.26791564, step = 5100 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.227\n",
      "INFO:tensorflow:loss = 0.3268251, step = 5200 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.902\n",
      "INFO:tensorflow:loss = 0.40923783, step = 5300 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.934\n",
      "INFO:tensorflow:loss = 0.5843144, step = 5400 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.606\n",
      "INFO:tensorflow:loss = 0.48011422, step = 5500 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.317\n",
      "INFO:tensorflow:loss = 0.48280215, step = 5600 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.955\n",
      "INFO:tensorflow:loss = 0.33587196, step = 5700 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.89\n",
      "INFO:tensorflow:loss = 0.35855174, step = 5800 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.138\n",
      "INFO:tensorflow:loss = 0.24788006, step = 5900 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.647\n",
      "INFO:tensorflow:loss = 0.3148149, step = 6000 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.364\n",
      "INFO:tensorflow:loss = 0.4141864, step = 6100 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.203\n",
      "INFO:tensorflow:loss = 0.13297163, step = 6200 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.212\n",
      "INFO:tensorflow:loss = 0.20173687, step = 6300 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.276\n",
      "INFO:tensorflow:loss = 0.33499396, step = 6400 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.046\n",
      "INFO:tensorflow:loss = 0.41856802, step = 6500 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.861\n",
      "INFO:tensorflow:loss = 0.2048442, step = 6600 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.602\n",
      "INFO:tensorflow:loss = 0.3399984, step = 6700 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.983\n",
      "INFO:tensorflow:loss = 0.22122437, step = 6800 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.544\n",
      "INFO:tensorflow:loss = 0.19643143, step = 6900 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.09\n",
      "INFO:tensorflow:loss = 0.64064354, step = 7000 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.132\n",
      "INFO:tensorflow:loss = 0.22124954, step = 7100 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.447\n",
      "INFO:tensorflow:loss = 0.20971237, step = 7200 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.999\n",
      "INFO:tensorflow:loss = 0.16129169, step = 7300 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.494\n",
      "INFO:tensorflow:loss = 0.30579644, step = 7400 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.465\n",
      "INFO:tensorflow:loss = 0.4057016, step = 7500 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.901\n",
      "INFO:tensorflow:loss = 0.2456577, step = 7600 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.488\n",
      "INFO:tensorflow:loss = 0.3936412, step = 7700 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.506\n",
      "INFO:tensorflow:loss = 0.20245323, step = 7800 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.332\n",
      "INFO:tensorflow:loss = 0.35722286, step = 7900 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.656\n",
      "INFO:tensorflow:loss = 0.16990636, step = 8000 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.997\n",
      "INFO:tensorflow:loss = 0.6287828, step = 8100 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.508\n",
      "INFO:tensorflow:loss = 0.17588383, step = 8200 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.549\n",
      "INFO:tensorflow:loss = 0.18546215, step = 8300 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.755\n",
      "INFO:tensorflow:loss = 0.13542034, step = 8400 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.191\n",
      "INFO:tensorflow:loss = 0.44768003, step = 8500 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.092\n",
      "INFO:tensorflow:loss = 0.24307676, step = 8600 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.021\n",
      "INFO:tensorflow:loss = 0.4776778, step = 8700 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.315\n",
      "INFO:tensorflow:loss = 0.18418168, step = 8800 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.938\n",
      "INFO:tensorflow:loss = 0.22789678, step = 8900 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.045\n",
      "INFO:tensorflow:loss = 0.16745017, step = 9000 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.922\n",
      "INFO:tensorflow:loss = 0.467163, step = 9100 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.262\n",
      "INFO:tensorflow:loss = 0.34340003, step = 9200 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.782\n",
      "INFO:tensorflow:loss = 0.30974537, step = 9300 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.251\n",
      "INFO:tensorflow:loss = 0.2304192, step = 9400 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.545\n",
      "INFO:tensorflow:loss = 0.27626723, step = 9500 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.656\n",
      "INFO:tensorflow:loss = 0.23143831, step = 9600 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.751\n",
      "INFO:tensorflow:loss = 0.29879913, step = 9700 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.688\n",
      "INFO:tensorflow:loss = 0.3489278, step = 9800 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.855\n",
      "INFO:tensorflow:loss = 0.3728788, step = 9900 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.895\n",
      "INFO:tensorflow:loss = 0.20531401, step = 10000 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.052\n",
      "INFO:tensorflow:loss = 0.11258387, step = 10100 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.819\n",
      "INFO:tensorflow:loss = 0.18271624, step = 10200 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.152\n",
      "INFO:tensorflow:loss = 0.32875344, step = 10300 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.623\n",
      "INFO:tensorflow:loss = 0.2062611, step = 10400 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.876\n",
      "INFO:tensorflow:loss = 0.26234186, step = 10500 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.77\n",
      "INFO:tensorflow:loss = 0.4108603, step = 10600 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.986\n",
      "INFO:tensorflow:loss = 0.19086802, step = 10700 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.819\n",
      "INFO:tensorflow:loss = 0.5194644, step = 10800 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.305\n",
      "INFO:tensorflow:loss = 0.450901, step = 10900 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.504\n",
      "INFO:tensorflow:loss = 0.42056885, step = 11000 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.915\n",
      "INFO:tensorflow:loss = 0.4996868, step = 11100 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.393\n",
      "INFO:tensorflow:loss = 0.17960522, step = 11200 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.668\n",
      "INFO:tensorflow:loss = 0.23665795, step = 11300 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.477\n",
      "INFO:tensorflow:loss = 0.19372389, step = 11400 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.46\n",
      "INFO:tensorflow:loss = 0.5570322, step = 11500 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.273\n",
      "INFO:tensorflow:loss = 0.2370515, step = 11600 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.086\n",
      "INFO:tensorflow:loss = 0.20350735, step = 11700 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.823\n",
      "INFO:tensorflow:loss = 0.18531553, step = 11800 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.771\n",
      "INFO:tensorflow:loss = 0.32976153, step = 11900 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.506\n",
      "INFO:tensorflow:loss = 0.14862192, step = 12000 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.783\n",
      "INFO:tensorflow:loss = 0.28603795, step = 12100 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.202\n",
      "INFO:tensorflow:loss = 0.35453865, step = 12200 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.088\n",
      "INFO:tensorflow:loss = 0.22069602, step = 12300 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.498\n",
      "INFO:tensorflow:loss = 0.11498226, step = 12400 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.421\n",
      "INFO:tensorflow:loss = 0.19894734, step = 12500 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.975\n",
      "INFO:tensorflow:loss = 0.3381021, step = 12600 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.479\n",
      "INFO:tensorflow:loss = 0.28499737, step = 12700 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.284\n",
      "INFO:tensorflow:loss = 0.29167834, step = 12800 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2516647, step = 12900 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.942\n",
      "INFO:tensorflow:loss = 0.55250883, step = 13000 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.515\n",
      "INFO:tensorflow:loss = 0.2429716, step = 13100 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.176\n",
      "INFO:tensorflow:loss = 0.36149848, step = 13200 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.112\n",
      "INFO:tensorflow:loss = 0.3518336, step = 13300 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.023\n",
      "INFO:tensorflow:loss = 0.27905267, step = 13400 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.126\n",
      "INFO:tensorflow:loss = 0.3723917, step = 13500 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.547\n",
      "INFO:tensorflow:loss = 0.13402195, step = 13600 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.921\n",
      "INFO:tensorflow:loss = 0.160181, step = 13700 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.781\n",
      "INFO:tensorflow:loss = 0.3622495, step = 13800 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.164\n",
      "INFO:tensorflow:loss = 0.11211859, step = 13900 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.672\n",
      "INFO:tensorflow:loss = 0.17309701, step = 14000 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.718\n",
      "INFO:tensorflow:loss = 0.40579495, step = 14100 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.406\n",
      "INFO:tensorflow:loss = 0.2523911, step = 14200 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.691\n",
      "INFO:tensorflow:loss = 0.35561866, step = 14300 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.674\n",
      "INFO:tensorflow:loss = 0.2915263, step = 14400 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.931\n",
      "INFO:tensorflow:loss = 0.114717394, step = 14500 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.986\n",
      "INFO:tensorflow:loss = 0.25691575, step = 14600 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.108\n",
      "INFO:tensorflow:loss = 0.23389155, step = 14700 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.906\n",
      "INFO:tensorflow:loss = 0.2631349, step = 14800 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.971\n",
      "INFO:tensorflow:loss = 0.38382295, step = 14900 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.065\n",
      "INFO:tensorflow:loss = 0.13852917, step = 15000 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.691\n",
      "INFO:tensorflow:loss = 0.23862419, step = 15100 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.633\n",
      "INFO:tensorflow:loss = 0.73502207, step = 15200 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.764\n",
      "INFO:tensorflow:loss = 0.32297647, step = 15300 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.256\n",
      "INFO:tensorflow:loss = 0.1164876, step = 15400 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.328\n",
      "INFO:tensorflow:loss = 0.17885607, step = 15500 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.065\n",
      "INFO:tensorflow:loss = 0.26520452, step = 15600 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.599\n",
      "INFO:tensorflow:loss = 0.12640627, step = 15700 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.297\n",
      "INFO:tensorflow:loss = 0.32942525, step = 15800 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.475\n",
      "INFO:tensorflow:loss = 0.39388716, step = 15900 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.023\n",
      "INFO:tensorflow:loss = 0.19813427, step = 16000 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.983\n",
      "INFO:tensorflow:loss = 0.15486893, step = 16100 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.304\n",
      "INFO:tensorflow:loss = 0.18204649, step = 16200 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.816\n",
      "INFO:tensorflow:loss = 0.31614378, step = 16300 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.221\n",
      "INFO:tensorflow:loss = 0.23160602, step = 16400 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.981\n",
      "INFO:tensorflow:loss = 0.27063426, step = 16500 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.569\n",
      "INFO:tensorflow:loss = 0.14171882, step = 16600 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.768\n",
      "INFO:tensorflow:loss = 0.2491111, step = 16700 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.474\n",
      "INFO:tensorflow:loss = 0.16165113, step = 16800 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.372\n",
      "INFO:tensorflow:loss = 0.35906684, step = 16900 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.913\n",
      "INFO:tensorflow:loss = 0.35904682, step = 17000 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.376\n",
      "INFO:tensorflow:loss = 0.24456987, step = 17100 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.437\n",
      "INFO:tensorflow:loss = 0.19653258, step = 17200 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.795\n",
      "INFO:tensorflow:loss = 0.14339212, step = 17300 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.075\n",
      "INFO:tensorflow:loss = 0.30652463, step = 17400 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.53\n",
      "INFO:tensorflow:loss = 0.11865709, step = 17500 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.286\n",
      "INFO:tensorflow:loss = 0.25716212, step = 17600 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.064\n",
      "INFO:tensorflow:loss = 0.37035713, step = 17700 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.389\n",
      "INFO:tensorflow:loss = 0.10839626, step = 17800 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.708\n",
      "INFO:tensorflow:loss = 0.25268325, step = 17900 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.627\n",
      "INFO:tensorflow:loss = 0.21714298, step = 18000 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.259\n",
      "INFO:tensorflow:loss = 0.44612312, step = 18100 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.278\n",
      "INFO:tensorflow:loss = 0.11299917, step = 18200 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.607\n",
      "INFO:tensorflow:loss = 0.06665376, step = 18300 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.47\n",
      "INFO:tensorflow:loss = 0.18367088, step = 18400 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.41\n",
      "INFO:tensorflow:loss = 0.23891795, step = 18500 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.991\n",
      "INFO:tensorflow:loss = 0.20036739, step = 18600 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.717\n",
      "INFO:tensorflow:loss = 0.36199012, step = 18700 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.042\n",
      "INFO:tensorflow:loss = 0.21872418, step = 18800 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.804\n",
      "INFO:tensorflow:loss = 0.41410965, step = 18900 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.983\n",
      "INFO:tensorflow:loss = 0.17230877, step = 19000 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.622\n",
      "INFO:tensorflow:loss = 0.39237082, step = 19100 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.097\n",
      "INFO:tensorflow:loss = 0.2702157, step = 19200 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.79\n",
      "INFO:tensorflow:loss = 0.3163082, step = 19300 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.808\n",
      "INFO:tensorflow:loss = 0.6252209, step = 19400 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.888\n",
      "INFO:tensorflow:loss = 0.1701432, step = 19500 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.791\n",
      "INFO:tensorflow:loss = 0.46021938, step = 19600 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.537\n",
      "INFO:tensorflow:loss = 0.1834906, step = 19700 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.593\n",
      "INFO:tensorflow:loss = 0.16557918, step = 19800 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.354\n",
      "INFO:tensorflow:loss = 0.15768324, step = 19900 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.804\n",
      "INFO:tensorflow:loss = 0.13298382, step = 20000 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.313\n",
      "INFO:tensorflow:loss = 0.17059898, step = 20100 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.636\n",
      "INFO:tensorflow:loss = 0.2507804, step = 20200 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.322\n",
      "INFO:tensorflow:loss = 0.22669327, step = 20300 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.827\n",
      "INFO:tensorflow:loss = 0.16125141, step = 20400 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.223\n",
      "INFO:tensorflow:loss = 0.1591712, step = 20500 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.852\n",
      "INFO:tensorflow:loss = 0.21869631, step = 20600 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.343\n",
      "INFO:tensorflow:loss = 0.32757133, step = 20700 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.512\n",
      "INFO:tensorflow:loss = 0.28680703, step = 20800 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.887\n",
      "INFO:tensorflow:loss = 0.20503205, step = 20900 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.031\n",
      "INFO:tensorflow:loss = 0.38991195, step = 21000 (0.225 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 475.745\n",
      "INFO:tensorflow:loss = 0.20468278, step = 21100 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.512\n",
      "INFO:tensorflow:loss = 0.21004833, step = 21200 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.514\n",
      "INFO:tensorflow:loss = 0.45350826, step = 21300 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.56\n",
      "INFO:tensorflow:loss = 0.27318355, step = 21400 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.499\n",
      "INFO:tensorflow:loss = 0.2144009, step = 21500 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.038\n",
      "INFO:tensorflow:loss = 0.2712891, step = 21600 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.878\n",
      "INFO:tensorflow:loss = 0.14156277, step = 21700 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.02\n",
      "INFO:tensorflow:loss = 0.11544184, step = 21800 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.627\n",
      "INFO:tensorflow:loss = 0.14515421, step = 21900 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.394\n",
      "INFO:tensorflow:loss = 0.20970288, step = 22000 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.516\n",
      "INFO:tensorflow:loss = 0.29351982, step = 22100 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.736\n",
      "INFO:tensorflow:loss = 0.27895486, step = 22200 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.693\n",
      "INFO:tensorflow:loss = 0.11282365, step = 22300 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.084\n",
      "INFO:tensorflow:loss = 0.48727462, step = 22400 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.97\n",
      "INFO:tensorflow:loss = 0.10278276, step = 22500 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.794\n",
      "INFO:tensorflow:loss = 0.11328554, step = 22600 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.702\n",
      "INFO:tensorflow:loss = 0.19185673, step = 22700 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.519\n",
      "INFO:tensorflow:loss = 0.3139474, step = 22800 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.176\n",
      "INFO:tensorflow:loss = 0.21755268, step = 22900 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.36\n",
      "INFO:tensorflow:loss = 0.5846449, step = 23000 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.186\n",
      "INFO:tensorflow:loss = 0.24451984, step = 23100 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.233\n",
      "INFO:tensorflow:loss = 0.20519377, step = 23200 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.515\n",
      "INFO:tensorflow:loss = 0.25261632, step = 23300 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.18\n",
      "INFO:tensorflow:loss = 0.24653079, step = 23400 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.959\n",
      "INFO:tensorflow:loss = 0.13765946, step = 23500 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.125\n",
      "INFO:tensorflow:loss = 0.09152234, step = 23600 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.8\n",
      "INFO:tensorflow:loss = 0.0705957, step = 23700 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.517\n",
      "INFO:tensorflow:loss = 0.35532653, step = 23800 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.453\n",
      "INFO:tensorflow:loss = 0.17595086, step = 23900 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.803\n",
      "INFO:tensorflow:loss = 0.19479962, step = 24000 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.578\n",
      "INFO:tensorflow:loss = 0.19246058, step = 24100 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.302\n",
      "INFO:tensorflow:loss = 0.2777963, step = 24200 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.79\n",
      "INFO:tensorflow:loss = 0.2871321, step = 24300 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.253\n",
      "INFO:tensorflow:loss = 0.22342797, step = 24400 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.46\n",
      "INFO:tensorflow:loss = 0.12641995, step = 24500 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.199\n",
      "INFO:tensorflow:loss = 0.34483945, step = 24600 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.371\n",
      "INFO:tensorflow:loss = 0.16904652, step = 24700 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.564\n",
      "INFO:tensorflow:loss = 0.2448534, step = 24800 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.358\n",
      "INFO:tensorflow:loss = 0.23126519, step = 24900 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.532\n",
      "INFO:tensorflow:loss = 0.30444852, step = 25000 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.249\n",
      "INFO:tensorflow:loss = 0.22956753, step = 25100 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.909\n",
      "INFO:tensorflow:loss = 0.2616881, step = 25200 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.123\n",
      "INFO:tensorflow:loss = 0.09231279, step = 25300 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.62\n",
      "INFO:tensorflow:loss = 0.18045427, step = 25400 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.974\n",
      "INFO:tensorflow:loss = 0.12885934, step = 25500 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.116\n",
      "INFO:tensorflow:loss = 0.20453015, step = 25600 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.708\n",
      "INFO:tensorflow:loss = 0.4349173, step = 25700 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.696\n",
      "INFO:tensorflow:loss = 0.17214762, step = 25800 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.562\n",
      "INFO:tensorflow:loss = 0.15670079, step = 25900 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.996\n",
      "INFO:tensorflow:loss = 0.15788296, step = 26000 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.093\n",
      "INFO:tensorflow:loss = 0.1351219, step = 26100 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.026\n",
      "INFO:tensorflow:loss = 0.08641848, step = 26200 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.683\n",
      "INFO:tensorflow:loss = 0.17914444, step = 26300 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.298\n",
      "INFO:tensorflow:loss = 0.21151915, step = 26400 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.177\n",
      "INFO:tensorflow:loss = 0.44274044, step = 26500 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.205\n",
      "INFO:tensorflow:loss = 0.12328228, step = 26600 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.963\n",
      "INFO:tensorflow:loss = 0.24469085, step = 26700 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.444\n",
      "INFO:tensorflow:loss = 0.30839446, step = 26800 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.819\n",
      "INFO:tensorflow:loss = 0.38991547, step = 26900 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.433\n",
      "INFO:tensorflow:loss = 0.23408504, step = 27000 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.572\n",
      "INFO:tensorflow:loss = 0.14334479, step = 27100 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.37\n",
      "INFO:tensorflow:loss = 0.25392303, step = 27200 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.65\n",
      "INFO:tensorflow:loss = 0.23754595, step = 27300 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.725\n",
      "INFO:tensorflow:loss = 0.19535023, step = 27400 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.322\n",
      "INFO:tensorflow:loss = 0.37264794, step = 27500 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.608\n",
      "INFO:tensorflow:loss = 0.18622547, step = 27600 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.748\n",
      "INFO:tensorflow:loss = 0.113042325, step = 27700 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.957\n",
      "INFO:tensorflow:loss = 0.16893287, step = 27800 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.28\n",
      "INFO:tensorflow:loss = 0.33302653, step = 27900 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.06\n",
      "INFO:tensorflow:loss = 0.18792447, step = 28000 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.188\n",
      "INFO:tensorflow:loss = 0.08212887, step = 28100 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.322\n",
      "INFO:tensorflow:loss = 0.5295212, step = 28200 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.983\n",
      "INFO:tensorflow:loss = 0.122738816, step = 28300 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.304\n",
      "INFO:tensorflow:loss = 0.24141312, step = 28400 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.228\n",
      "INFO:tensorflow:loss = 0.28980032, step = 28500 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.163\n",
      "INFO:tensorflow:loss = 0.11208929, step = 28600 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.513\n",
      "INFO:tensorflow:loss = 0.34667698, step = 28700 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.743\n",
      "INFO:tensorflow:loss = 0.4451693, step = 28800 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.917\n",
      "INFO:tensorflow:loss = 0.1527405, step = 28900 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.252\n",
      "INFO:tensorflow:loss = 0.2635801, step = 29000 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.364\n",
      "INFO:tensorflow:loss = 0.31047666, step = 29100 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.13354865, step = 29200 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.457\n",
      "INFO:tensorflow:loss = 0.1612702, step = 29300 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.147\n",
      "INFO:tensorflow:loss = 0.13857025, step = 29400 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.582\n",
      "INFO:tensorflow:loss = 0.1596251, step = 29500 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.75\n",
      "INFO:tensorflow:loss = 0.11997793, step = 29600 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.309\n",
      "INFO:tensorflow:loss = 0.16250257, step = 29700 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.584\n",
      "INFO:tensorflow:loss = 0.30367324, step = 29800 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.152\n",
      "INFO:tensorflow:loss = 0.2399237, step = 29900 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.918\n",
      "INFO:tensorflow:loss = 0.07693576, step = 30000 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.055\n",
      "INFO:tensorflow:loss = 0.09361076, step = 30100 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.643\n",
      "INFO:tensorflow:loss = 0.18417649, step = 30200 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.634\n",
      "INFO:tensorflow:loss = 0.1678, step = 30300 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.347\n",
      "INFO:tensorflow:loss = 0.3178361, step = 30400 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.865\n",
      "INFO:tensorflow:loss = 0.059676472, step = 30500 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.964\n",
      "INFO:tensorflow:loss = 0.19378226, step = 30600 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.276\n",
      "INFO:tensorflow:loss = 0.17562932, step = 30700 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.151\n",
      "INFO:tensorflow:loss = 0.21987978, step = 30800 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.603\n",
      "INFO:tensorflow:loss = 0.20623098, step = 30900 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.551\n",
      "INFO:tensorflow:loss = 0.16521452, step = 31000 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.804\n",
      "INFO:tensorflow:loss = 0.14179724, step = 31100 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.158\n",
      "INFO:tensorflow:loss = 0.22553486, step = 31200 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.381\n",
      "INFO:tensorflow:loss = 0.2209927, step = 31300 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.587\n",
      "INFO:tensorflow:loss = 0.16574179, step = 31400 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.682\n",
      "INFO:tensorflow:loss = 0.15765613, step = 31500 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.861\n",
      "INFO:tensorflow:loss = 0.33305457, step = 31600 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.804\n",
      "INFO:tensorflow:loss = 0.17237255, step = 31700 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.457\n",
      "INFO:tensorflow:loss = 0.104255855, step = 31800 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.284\n",
      "INFO:tensorflow:loss = 0.1555558, step = 31900 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.746\n",
      "INFO:tensorflow:loss = 0.3184748, step = 32000 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.832\n",
      "INFO:tensorflow:loss = 0.12958455, step = 32100 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.587\n",
      "INFO:tensorflow:loss = 0.12335085, step = 32200 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.21\n",
      "INFO:tensorflow:loss = 0.36813304, step = 32300 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.041\n",
      "INFO:tensorflow:loss = 0.46073765, step = 32400 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.762\n",
      "INFO:tensorflow:loss = 0.089815706, step = 32500 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.084\n",
      "INFO:tensorflow:loss = 0.13185222, step = 32600 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.734\n",
      "INFO:tensorflow:loss = 0.13309562, step = 32700 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.114\n",
      "INFO:tensorflow:loss = 0.27739412, step = 32800 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.261\n",
      "INFO:tensorflow:loss = 0.13196896, step = 32900 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.504\n",
      "INFO:tensorflow:loss = 0.32886067, step = 33000 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.988\n",
      "INFO:tensorflow:loss = 0.13447657, step = 33100 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.104\n",
      "INFO:tensorflow:loss = 0.14654636, step = 33200 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.575\n",
      "INFO:tensorflow:loss = 0.16206051, step = 33300 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.913\n",
      "INFO:tensorflow:loss = 0.40346444, step = 33400 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.416\n",
      "INFO:tensorflow:loss = 0.16384642, step = 33500 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.35\n",
      "INFO:tensorflow:loss = 0.18344486, step = 33600 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.449\n",
      "INFO:tensorflow:loss = 0.24357712, step = 33700 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.019\n",
      "INFO:tensorflow:loss = 0.21259159, step = 33800 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.238\n",
      "INFO:tensorflow:loss = 0.17126876, step = 33900 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.378\n",
      "INFO:tensorflow:loss = 0.30432758, step = 34000 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.571\n",
      "INFO:tensorflow:loss = 0.25881946, step = 34100 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.803\n",
      "INFO:tensorflow:loss = 0.27657723, step = 34200 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.371\n",
      "INFO:tensorflow:loss = 0.15743056, step = 34300 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.791\n",
      "INFO:tensorflow:loss = 0.16412355, step = 34400 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.794\n",
      "INFO:tensorflow:loss = 0.43144426, step = 34500 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.279\n",
      "INFO:tensorflow:loss = 0.24493542, step = 34600 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.2\n",
      "INFO:tensorflow:loss = 0.33732766, step = 34700 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.373\n",
      "INFO:tensorflow:loss = 0.07556537, step = 34800 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.427\n",
      "INFO:tensorflow:loss = 0.34953862, step = 34900 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.089\n",
      "INFO:tensorflow:loss = 0.11604039, step = 35000 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.486\n",
      "INFO:tensorflow:loss = 0.11909937, step = 35100 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.161\n",
      "INFO:tensorflow:loss = 0.088107154, step = 35200 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.837\n",
      "INFO:tensorflow:loss = 0.1723156, step = 35300 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.899\n",
      "INFO:tensorflow:loss = 0.309062, step = 35400 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.843\n",
      "INFO:tensorflow:loss = 0.108546294, step = 35500 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.361\n",
      "INFO:tensorflow:loss = 0.16039258, step = 35600 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.349\n",
      "INFO:tensorflow:loss = 0.107201576, step = 35700 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.635\n",
      "INFO:tensorflow:loss = 0.23511527, step = 35800 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.416\n",
      "INFO:tensorflow:loss = 0.12805098, step = 35900 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.474\n",
      "INFO:tensorflow:loss = 0.22463936, step = 36000 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.393\n",
      "INFO:tensorflow:loss = 0.093649365, step = 36100 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.009\n",
      "INFO:tensorflow:loss = 0.22127847, step = 36200 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.872\n",
      "INFO:tensorflow:loss = 0.29230142, step = 36300 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.553\n",
      "INFO:tensorflow:loss = 0.13718724, step = 36400 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.68\n",
      "INFO:tensorflow:loss = 0.1496355, step = 36500 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.13\n",
      "INFO:tensorflow:loss = 0.4537528, step = 36600 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.61\n",
      "INFO:tensorflow:loss = 0.07853499, step = 36700 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.882\n",
      "INFO:tensorflow:loss = 0.09314547, step = 36800 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.311\n",
      "INFO:tensorflow:loss = 0.34665677, step = 36900 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.409\n",
      "INFO:tensorflow:loss = 0.051925078, step = 37000 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.681\n",
      "INFO:tensorflow:loss = 0.26270536, step = 37100 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.277\n",
      "INFO:tensorflow:loss = 0.13705322, step = 37200 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.029\n",
      "INFO:tensorflow:loss = 0.18326622, step = 37300 (0.224 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 443.51\n",
      "INFO:tensorflow:loss = 0.23833331, step = 37400 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.467\n",
      "INFO:tensorflow:loss = 0.16198583, step = 37500 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.522\n",
      "INFO:tensorflow:loss = 0.21523859, step = 37600 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.536\n",
      "INFO:tensorflow:loss = 0.23297766, step = 37700 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.618\n",
      "INFO:tensorflow:loss = 0.113907434, step = 37800 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.638\n",
      "INFO:tensorflow:loss = 0.11536718, step = 37900 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.036\n",
      "INFO:tensorflow:loss = 0.18860286, step = 38000 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.628\n",
      "INFO:tensorflow:loss = 0.19688633, step = 38100 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.425\n",
      "INFO:tensorflow:loss = 0.20131367, step = 38200 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.163\n",
      "INFO:tensorflow:loss = 0.23716137, step = 38300 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.339\n",
      "INFO:tensorflow:loss = 0.121223085, step = 38400 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.753\n",
      "INFO:tensorflow:loss = 0.16985062, step = 38500 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.456\n",
      "INFO:tensorflow:loss = 0.14209084, step = 38600 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.66\n",
      "INFO:tensorflow:loss = 0.13686118, step = 38700 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.814\n",
      "INFO:tensorflow:loss = 0.13603184, step = 38800 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.065\n",
      "INFO:tensorflow:loss = 0.2904203, step = 38900 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.556\n",
      "INFO:tensorflow:loss = 0.21058758, step = 39000 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.474\n",
      "INFO:tensorflow:loss = 0.14094017, step = 39100 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.391\n",
      "INFO:tensorflow:loss = 0.04855404, step = 39200 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.495\n",
      "INFO:tensorflow:loss = 0.24060917, step = 39300 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.84\n",
      "INFO:tensorflow:loss = 0.20998566, step = 39400 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.354\n",
      "INFO:tensorflow:loss = 0.20067331, step = 39500 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.079\n",
      "INFO:tensorflow:loss = 0.144312, step = 39600 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.2\n",
      "INFO:tensorflow:loss = 0.15818666, step = 39700 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.099\n",
      "INFO:tensorflow:loss = 0.25513107, step = 39800 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.691\n",
      "INFO:tensorflow:loss = 0.1869558, step = 39900 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.755\n",
      "INFO:tensorflow:loss = 0.1463321, step = 40000 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.997\n",
      "INFO:tensorflow:loss = 0.24788474, step = 40100 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.23\n",
      "INFO:tensorflow:loss = 0.20134622, step = 40200 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.186\n",
      "INFO:tensorflow:loss = 0.16213197, step = 40300 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.759\n",
      "INFO:tensorflow:loss = 0.24891853, step = 40400 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.431\n",
      "INFO:tensorflow:loss = 0.099394344, step = 40500 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.674\n",
      "INFO:tensorflow:loss = 0.08078953, step = 40600 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.76\n",
      "INFO:tensorflow:loss = 0.27486703, step = 40700 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.924\n",
      "INFO:tensorflow:loss = 0.14930388, step = 40800 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.128\n",
      "INFO:tensorflow:loss = 0.16032292, step = 40900 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.413\n",
      "INFO:tensorflow:loss = 0.083859116, step = 41000 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.772\n",
      "INFO:tensorflow:loss = 0.09356317, step = 41100 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.125\n",
      "INFO:tensorflow:loss = 0.18271677, step = 41200 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.682\n",
      "INFO:tensorflow:loss = 0.15511295, step = 41300 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.673\n",
      "INFO:tensorflow:loss = 0.24505249, step = 41400 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.422\n",
      "INFO:tensorflow:loss = 0.14416136, step = 41500 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.993\n",
      "INFO:tensorflow:loss = 0.23222737, step = 41600 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.314\n",
      "INFO:tensorflow:loss = 0.324507, step = 41700 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.858\n",
      "INFO:tensorflow:loss = 0.11225557, step = 41800 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.868\n",
      "INFO:tensorflow:loss = 0.14791673, step = 41900 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.96\n",
      "INFO:tensorflow:loss = 0.149398, step = 42000 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.931\n",
      "INFO:tensorflow:loss = 0.08824818, step = 42100 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.242\n",
      "INFO:tensorflow:loss = 0.42381912, step = 42200 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.8\n",
      "INFO:tensorflow:loss = 0.13168268, step = 42300 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.276\n",
      "INFO:tensorflow:loss = 0.10249029, step = 42400 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.384\n",
      "INFO:tensorflow:loss = 0.31327888, step = 42500 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.914\n",
      "INFO:tensorflow:loss = 0.0878693, step = 42600 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.207\n",
      "INFO:tensorflow:loss = 0.2724233, step = 42700 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.253\n",
      "INFO:tensorflow:loss = 0.19811502, step = 42800 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.59\n",
      "INFO:tensorflow:loss = 0.14871812, step = 42900 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.02\n",
      "INFO:tensorflow:loss = 0.20038672, step = 43000 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.961\n",
      "INFO:tensorflow:loss = 0.20758122, step = 43100 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.537\n",
      "INFO:tensorflow:loss = 0.10922716, step = 43200 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.692\n",
      "INFO:tensorflow:loss = 0.27471238, step = 43300 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.008\n",
      "INFO:tensorflow:loss = 0.22668704, step = 43400 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.74\n",
      "INFO:tensorflow:loss = 0.13318741, step = 43500 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.877\n",
      "INFO:tensorflow:loss = 0.15118647, step = 43600 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.508\n",
      "INFO:tensorflow:loss = 0.118843496, step = 43700 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.394\n",
      "INFO:tensorflow:loss = 0.2014021, step = 43800 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.995\n",
      "INFO:tensorflow:loss = 0.086082526, step = 43900 (0.212 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 44000 into /tmp/tmpxbj91xes/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.10369904.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f18a00fb8d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "dnn_clf = tf.estimator.DNNClassifier(hidden_units=[300,100], n_classes=10,\n",
    "                                     feature_columns=feature_cols)\n",
    "\n",
    "input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, num_epochs=40, batch_size=50, shuffle=True)\n",
    "dnn_clf.train(input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-18T21:50:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpxbj91xes/model.ckpt-44000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-18-21:50:33\n",
      "INFO:tensorflow:Saving dict for global step 44000: accuracy = 0.9488, average_loss = 0.18019786, global_step = 44000, loss = 0.17890291\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 44000: /tmp/tmpxbj91xes/model.ckpt-44000\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test}, y=y_test, shuffle=False)\n",
    "eval_results = dnn_clf.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9488,\n",
       " 'average_loss': 0.18019786,\n",
       " 'loss': 0.17890291,\n",
       " 'global_step': 44000}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpxbj91xes/model.ckpt-44000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logits': array([ 0.25431165, -3.9832058 ,  1.7883002 ,  2.7589452 , -3.0482638 ,\n",
       "        -0.64774305, -7.0888457 ,  9.104177  , -1.8259383 ,  1.6111878 ],\n",
       "       dtype=float32),\n",
       " 'probabilities': array([1.4294300e-04, 2.0645834e-06, 6.6277420e-04, 1.7494904e-03,\n",
       "        5.2586311e-06, 5.7996989e-05, 9.2484719e-08, 9.9680638e-01,\n",
       "        1.7853439e-05, 5.5519660e-04], dtype=float32),\n",
       " 'class_ids': array([7]),\n",
       " 'classes': array([b'7'], dtype=object),\n",
       " 'all_class_ids': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32),\n",
       " 'all_classes': array([b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', b'9'],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_iter = dnn_clf.predict(input_fn=test_input_fn)\n",
    "y_pred = list(y_pred_iter)\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DNNClassifier` class creates all the neuron layers, based on the ReLU activation function (change `activation_fn` hyperparameter). The output layer relies on the softmax function, and the cost function is cross entropy.\n",
    "\n",
    "### Training a DNN Using Plain TensorFlow\n",
    "\n",
    "Mini-batch Gradient Descent to train it on the MNIST dataset. 1st step - construction phase, building the TensorFlow graph. 2nd step - the execution phase, where you actually run the graph to train the model.\n",
    "\n",
    "#### Construction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'reset_default_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c91aa8a64c9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'reset_default_graph'"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)    # helps the algorithm converge much faster\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")\n",
    "    y_proba = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `logits` is the output of the neural network _before_ going through the `softmax` activation function: for optimization reasons, we will handle the softmax computation later.\n",
    "\n",
    "You can use TensorFlow's `tf.layers.dense()` function to create a fully connected layer. methods: `name`, `activation`, `kernel_initializer`, the default `activation` is now `None`.\n",
    "\n",
    "The `sparse_softmax_cross_entropy_with_logits()` function is equivalent to applying the softmax activation function and then computing the cross entropy, but it is more efficient, and it properly takes care of corner cases like logits equal to 0. There is also another function called `softmax_cross_entropy_with_logits()`, which takes labels in the form of one-hot vectors.\n",
    "\n",
    "#### Execution Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                        y: mnist.test.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./logs/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Neural Network\n",
    "\n",
    "First the code loads the model parameters from disk. Then it loads some new images that you want to classify. Remember to apply the same feature scaling as for the training data (in this case, scale it from 0 to 1). Then the code evaluates the `logits` node. If you wanted to know all the estimated class probabilities, you would need to apply the `softmax()` function to the logits, but if you just want to predict a class, you can simply pick the class that has the highest logit value (using the `argmax()` function does the trick)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./logs/my_model_final.ckpt\")\n",
    "    X_new_scaled = [...] # some new images (scaled from 0 to 1)\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning Neural Network Hyperparameters\n",
    "\n",
    "The flexibility of neural networks is also one of their main drawbacks: there are many hyperparameters to tweak. Any _network topology_, number of layers, number of neurons per layer, type of activation function, weight initialization logic. \n",
    "\n",
    "It is much better to use randomized search over grid search. Another option is to use a tool such as Oscar (http://oscar.calldesk.ai/), which implements more complex algorithms to help you find a good set of hyperparameters quickly.\n",
    "\n",
    "#### Number of Hidden Layers\n",
    "\n",
    "MLP with just one hidden layer can model even the most complex functions provided it has enough neurons. However, deep networks have a much higher parameter efficiency than shallow ones: they can model complex functions using exponentially fewer neurons than shallow nets, making them much faster to train.\n",
    "\n",
    "Real-world data is often structured in such a hierarchical way and DNNs automatically take advantage of this fact.\n",
    "\n",
    "Not only does this hierarchical architecture help DNNs converge faster to a good solution, it also\n",
    "improves their ability to generalize to new datasets. \n",
    "\n",
    "In summary, for many problems you can start with just one or two hidden layers and it will work just fine. For more complex problems, you can gradually ramp up the number of hidden layers, until you start overfitting the training set. Very complex tasks, typically require networks with dozens of layers (or even hundreds, but not fully connected ones), and they need a huge amount of training data. However, you will rarely have to train such networks from scratch: it is much more common to reuse parts of a pretrained state-of-the-art network that performs a similar task. Training will be a lot faster and require much less data.\n",
    "\n",
    "#### Number of Neurons per Hidden Layer\n",
    "\n",
    "As for the hidden layers, a common practice is to size them to form a funnel, with fewer and fewer neurons at each layer - the rationale being that many low-level features can coalesce into far fewer high-level features. However, this practice is not as common now, and you may simply use the same size for all hidden layers. Just like for the number of layers, you can try increasing the number of neurons gradually until the network starts overfitting. In general you will get more bang for the buck by increasing the number of layers than the number of neurons per layer.\n",
    "\n",
    "A simpler approach is to pick a model with more layers and neurons than you actually need, then use _early stopping_ to prevent it from overfitting (and other regularization techniques, especially _dropout_). This has been dubbed the stretch pants approach: instead of wasting time looking for pants that perfectly match your size, just use large stretch pants that will shrink down to the right size.\n",
    "\n",
    "#### Activation Functions\n",
    "\n",
    "In most cases you can use the ReLU activation function in the hidden layers (or one of its variants). It is a bit faster to compute than other activation functions, and Gradient Descent does not get stuck as much on plateaus, thanks to the fact that it does not saturate for large input values (as opposed to the logistic function or the hyperbolic tangent function, which saturate at 1).\n",
    "\n",
    "For the output layer, the softmax activation function is generally a good choice for classification tasks (when the classes are mutually exclusive). For regression tasks, you can simply use no activation function at all."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
