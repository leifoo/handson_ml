{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10. Introduction to Artificial Neural Networks\n",
    "\n",
    "Key idea inspired _artificial neural networks_(ANNs): study brain's architecture for inspiration on how to build an intelligent machine.\n",
    "\n",
    "ANNs are the very core of Deep Learning. They are versatile, powerful, and scalable, making them ideal to tackle large and highly complex Machine Learning tasks.\n",
    "\n",
    "### From Biological to Artificial Neurons\n",
    "\n",
    "ANNS first introduced as _propositional logic_ in 1943 by Warren McCulloch and Walter Pitts. \n",
    "\n",
    "In the early 1980s there was a revival of interest in ANNs as new network architectures were invented and better training techniques were developed. But by the 1990s, powerful alternative Machine Learning techniques such as\n",
    "Support Vector Machines.\n",
    "\n",
    "Reasons to believe this wave of interest in ANNs is different and will have a much more profound impact on our lives:\n",
    " - Huge quantity of data available to train neural networks, and ANNs frequently outperform other ML techniques on very large and complex problems.\n",
    " - Computing power (Moore's Law, GPUs)\n",
    " - The training algorithms have been improved.\n",
    " - Some theoretical limitations of ANNs have turned out to be benign in practice.\n",
    " - ANNs seem to have entered a virtuous circle of funding and progress.\n",
    " \n",
    "#### Biological Neurons\n",
    "\n",
    "Each neuron typically connected to thousands of other neurons. Highly complex computations can be performed by a vast network of fairly simple neurons.\n",
    "\n",
    "<div style=\"width:400 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig10-1.png\" width=400px alt=\"fig10-1\" style=\"padding-bottom:1.0em;padding-top:2.0em;\"></center>_Figure 10-1. Biological neuron_</div>\n",
    "\n",
    "#### Logical Computations with Neurons\n",
    "\n",
    "_Artificial neuron_: one or more binary (on/off) inputs and one binary output. (Such simplified model can build a network of artificial neurons that computes any logical proposition.)\n",
    "\n",
    "#### The perceptron\n",
    "\n",
    "_Perceptron_: one of the simplest ANN architectures, invented in 1957 by Frank Rosenblatt. It is based on a slightly different artificial neuron called a _linear threshold unit_ (LTU): the inputs and output are now numbers (instead of binary on/off values) and each input connection is associated with a weight.\n",
    "\n",
    "<div style=\"width:400 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig10-4.png\" width=400px alt=\"fig10-4\" style=\"padding-bottom:1.0em;padding-top:2.0em;\"></center>_Figure 10-4. Linear shreshold unit_</div>\n",
    "\n",
    "_Common step functions used in Perceptrons_\n",
    "\n",
    "$$heaviside \\ (z) = \\left\\{\\begin{matrix}\n",
    "0 \\ \\ if \\ z<0\n",
    "\\\\ \n",
    "1 \\ \\ if \\ z \\ge 0\n",
    "\\end{matrix}\\right. \\ \\ \\ \\ \\ \\ \\ sgn \\ (z) = \\left\\{\\begin{matrix}\n",
    "-1 \\ \\ if \\ z<0\n",
    "\\\\ \n",
    "0 \\ \\ if \\ z=0\n",
    "\\\\\n",
    "1 \\ \\ if \\ z \\ge 0\n",
    "\\end{matrix}\\right.$$\n",
    "\n",
    "A Perceptron is simply composed of a single layer of LTUs, with each neuron connected to all the inputs.\n",
    "These connections are often represented using special passthrough neurons called _input neurons_: they just\n",
    "output whatever input they are fed. Moreover, an extra bias feature is generally added ($x_0 = 1$). This bias\n",
    "feature is typically represented using a special type of neuron called a _bias neuron_, which just outputs 1\n",
    "all the time.\n",
    "\n",
    "<div style=\"width:400 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig10-5.png\" width=400px alt=\"fig10-5\" style=\"padding-bottom:1.0em;padding-top:2.0em;\"></center>_Figure 10-5. Perceptron diagram. This Perceptron can classify instances simultaneously into three different binary classes, which makes it a multioutput\n",
    "classifier._</div>\n",
    "\n",
    "How is a Perceptron trained?\n",
    "\n",
    "Hebb's rule (Hebbian learning): the connection weight between two neurons is increased whenever they have the same\n",
    "output.\n",
    "\n",
    "Perceptrons are trained using a variant of this rule that takes into account the error made by the network; it does not reinforce connections that lead to the wrong output. More specifically, the Perceptron is fed one training instance at a time, and for each instance it makes its predictions. For every output neuron that produced a wrong prediction, it reinforces the connection weights from the inputs that would have contributed to the correct prediction. The rule is shown as\n",
    "\n",
    "_Perceptron learning rule (weight update)_\n",
    "\n",
    "$$ w_{i,j}^{next\\_step} = w_{i,j} + \\eta(\\hat{y}_j - y_j)x_i$$\n",
    "\n",
    "_Perceptron convergence Theorem_: if the training instances are linearly separable, this algorithm would converge to a solution. \n",
    "\n",
    "Prefer Logistic Regression over Perceptrons, because instead of outputting a class probability, Perceptrons just make predictions based on a hard threshold.\n",
    "\n",
    "_Multi-Layer Perceptron_ (MLP) can eliminate some of the limitations of Perceptrons, while single-layer perceptrons are incapable of solving some trivial problems.\n",
    "\n",
    "#### Multi_layer Perceptron and Backpropagation\n",
    "\n",
    "An MLP is composed of one (passthrough) input layer, one or more layers of LTUs, called _hidden layers_, and one final layer of LTUs called the _output layer_. Every layer except the output layer includes a bias neuron and is fully connected to the next layer. \n",
    "\n",
    "_Deep neural network_ (DNN): ANN has two or more hidden layers.\n",
    "\n",
    "<div style=\"width:400 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig10-7.png\" width=400px alt=\"fig10-7\" style=\"padding-bottom:1.0em;padding-top:2.0em;\"></center>_Figure 10-7. Multi-Layer Perceptron_</div>\n",
    "\n",
    "Backpropagation training algorithm, same as Gradient Descent using reverse-mode autodiff: For each training instance the backpropagation algorithm first makes a prediction (forward pass), measures the error, then goes through each layer in reverse to measure the error contribution from each connection (reverse pass), and finally slightly tweaks the connection weights to reduce the error (Gradient Descent step).\n",
    "\n",
    "_Activation (Step) function_ with well-defined nonzero derivative everywhere:\n",
    " - _Logistic function_, $\\sigma (z)=1/(1+\\exp(z)) \\ \\ \\in [0,1]$ \n",
    " - _Hyperbolic tangent function_, $\\tanh (z) = 2\\sigma (2z)-1 \\ \\ \\in [-1,1]$, make each layer's output normalized (i.e., centered around 0) at the beginning of training. Speed up convergence.\n",
    " - _ReLU function_, $ReLU(z)=\\max(0,z) \\ \\  \\in [0,\\infty)$, fast to compute gradient.\n",
    " \n",
    "<div style=\"width:400 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig10-8.png\" width=400px alt=\"fig10-8\" style=\"padding-bottom:1.0em;padding-top:2.0em;\"></center>_Figure 10-8. Activation functions ans their derivatives_</div>\n",
    "\n",
    "An MLP is often used for classification, with each output corresponding to a different binary class. When the classes are exclusive, the output layer is typically modified by replacing the individual activation\n",
    "functions by a shared _softmax_ function. The output of each neuron corresponds to the estimated probability of the corresponding class. Note that the signal flows only in one direction (from the inputs to the outputs), so this architecture is an example of a _feedforward neural network_ (FNN).\n",
    "\n",
    "<div style=\"width:400 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig10-9.png\" width=400px alt=\"fig10-9\" style=\"padding-bottom:1.0em;padding-top:2.0em;\"></center>_Figure 10-9. A modern MLP (including ReLU and softmax) for classification_</div>\n",
    "\n",
    "<font color=blue>_NOTE_</font>\n",
    ">Biological neurons seem to implement a roughly sigmoid (S-shaped) activation function, so researchers stuck to sigmoid functions for a very long time. But it turns out that the ReLU activation function generally works better in ANNs.\n",
    "\n",
    "### Training an MLP with TensorFlow's High-Level API\n",
    "\n",
    "Trains a DNN for classification with two hidden layers (one with 300 neurons, and the other with 100 neurons) and a softmax output layer with 10 neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpj1_i_7bd\n",
      "INFO:tensorflow:Using config: {'_evaluation_master': '', '_global_id_in_cluster': 0, '_num_ps_replicas': 0, '_master': '', '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_save_summary_steps': 100, '_is_chief': True, '_num_worker_replicas': 1, '_save_checkpoints_steps': None, '_model_dir': '/tmp/tmpj1_i_7bd', '_tf_random_seed': None, '_task_id': 0, '_save_checkpoints_secs': 600, '_service': None, '_session_config': None, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd876fa0f60>, '_log_step_count_steps': 100, '_keep_checkpoint_max': 5}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpj1_i_7bd/model.ckpt.\n",
      "INFO:tensorflow:step = 0, loss = 114.93579\n",
      "INFO:tensorflow:global_step/sec: 259.287\n",
      "INFO:tensorflow:step = 100, loss = 8.290704 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.869\n",
      "INFO:tensorflow:step = 200, loss = 10.732464 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.827\n",
      "INFO:tensorflow:step = 300, loss = 4.067537 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.434\n",
      "INFO:tensorflow:step = 400, loss = 9.906698 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.671\n",
      "INFO:tensorflow:step = 500, loss = 19.332918 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.175\n",
      "INFO:tensorflow:step = 600, loss = 6.2974305 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.086\n",
      "INFO:tensorflow:step = 700, loss = 6.243603 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.939\n",
      "INFO:tensorflow:step = 800, loss = 6.162698 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.517\n",
      "INFO:tensorflow:step = 900, loss = 12.440324 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.297\n",
      "INFO:tensorflow:step = 1000, loss = 11.617707 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.156\n",
      "INFO:tensorflow:step = 1100, loss = 0.69682026 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.352\n",
      "INFO:tensorflow:step = 1200, loss = 1.5169028 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.032\n",
      "INFO:tensorflow:step = 1300, loss = 2.3844252 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.884\n",
      "INFO:tensorflow:step = 1400, loss = 0.8254401 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.965\n",
      "INFO:tensorflow:step = 1500, loss = 11.485088 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.76\n",
      "INFO:tensorflow:step = 1600, loss = 7.3827863 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.809\n",
      "INFO:tensorflow:step = 1700, loss = 4.616459 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.619\n",
      "INFO:tensorflow:step = 1800, loss = 9.077316 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.123\n",
      "INFO:tensorflow:step = 1900, loss = 1.3768711 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.261\n",
      "INFO:tensorflow:step = 2000, loss = 1.0028824 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.915\n",
      "INFO:tensorflow:step = 2100, loss = 1.966898 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.832\n",
      "INFO:tensorflow:step = 2200, loss = 3.1630096 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.508\n",
      "INFO:tensorflow:step = 2300, loss = 1.4816004 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.255\n",
      "INFO:tensorflow:step = 2400, loss = 0.40491495 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.168\n",
      "INFO:tensorflow:step = 2500, loss = 0.80741125 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.385\n",
      "INFO:tensorflow:step = 2600, loss = 0.67856014 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.793\n",
      "INFO:tensorflow:step = 2700, loss = 2.2964365 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.672\n",
      "INFO:tensorflow:step = 2800, loss = 7.5575166 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.096\n",
      "INFO:tensorflow:step = 2900, loss = 3.8874657 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.225\n",
      "INFO:tensorflow:step = 3000, loss = 0.30583638 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.111\n",
      "INFO:tensorflow:step = 3100, loss = 2.387917 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.689\n",
      "INFO:tensorflow:step = 3200, loss = 0.4423747 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.877\n",
      "INFO:tensorflow:step = 3300, loss = 15.032637 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.876\n",
      "INFO:tensorflow:step = 3400, loss = 4.6355205 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.203\n",
      "INFO:tensorflow:step = 3500, loss = 4.9169283 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.701\n",
      "INFO:tensorflow:step = 3600, loss = 1.2355852 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.031\n",
      "INFO:tensorflow:step = 3700, loss = 0.85609156 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.252\n",
      "INFO:tensorflow:step = 3800, loss = 2.725216 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.065\n",
      "INFO:tensorflow:step = 3900, loss = 2.249071 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.451\n",
      "INFO:tensorflow:step = 4000, loss = 0.8296145 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.21\n",
      "INFO:tensorflow:step = 4100, loss = 7.2620316 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.497\n",
      "INFO:tensorflow:step = 4200, loss = 3.9810476 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.793\n",
      "INFO:tensorflow:step = 4300, loss = 7.0488596 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.559\n",
      "INFO:tensorflow:step = 4400, loss = 4.1165204 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.268\n",
      "INFO:tensorflow:step = 4500, loss = 6.359284 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.242\n",
      "INFO:tensorflow:step = 4600, loss = 0.5680206 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.176\n",
      "INFO:tensorflow:step = 4700, loss = 0.18109146 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.918\n",
      "INFO:tensorflow:step = 4800, loss = 0.4040772 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.998\n",
      "INFO:tensorflow:step = 4900, loss = 0.5870065 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.603\n",
      "INFO:tensorflow:step = 5000, loss = 1.2273453 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.933\n",
      "INFO:tensorflow:step = 5100, loss = 2.4449027 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.854\n",
      "INFO:tensorflow:step = 5200, loss = 0.08103167 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.766\n",
      "INFO:tensorflow:step = 5300, loss = 1.552398 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.874\n",
      "INFO:tensorflow:step = 5400, loss = 3.454167 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.404\n",
      "INFO:tensorflow:step = 5500, loss = 8.557803 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.77\n",
      "INFO:tensorflow:step = 5600, loss = 0.5351677 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.928\n",
      "INFO:tensorflow:step = 5700, loss = 0.54996145 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.075\n",
      "INFO:tensorflow:step = 5800, loss = 0.24521938 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.228\n",
      "INFO:tensorflow:step = 5900, loss = 0.8758366 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.409\n",
      "INFO:tensorflow:step = 6000, loss = 1.0877392 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.237\n",
      "INFO:tensorflow:step = 6100, loss = 0.4679286 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.733\n",
      "INFO:tensorflow:step = 6200, loss = 2.514618 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.595\n",
      "INFO:tensorflow:step = 6300, loss = 0.14287661 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.133\n",
      "INFO:tensorflow:step = 6400, loss = 3.7255964 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.178\n",
      "INFO:tensorflow:step = 6500, loss = 1.0535071 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.779\n",
      "INFO:tensorflow:step = 6600, loss = 1.962812 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.876\n",
      "INFO:tensorflow:step = 6700, loss = 0.6482417 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.643\n",
      "INFO:tensorflow:step = 6800, loss = 3.863318 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.235\n",
      "INFO:tensorflow:step = 6900, loss = 0.5138833 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.175\n",
      "INFO:tensorflow:step = 7000, loss = 0.6459025 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.091\n",
      "INFO:tensorflow:step = 7100, loss = 0.060694598 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.789\n",
      "INFO:tensorflow:step = 7200, loss = 0.499418 (0.336 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 307.679\n",
      "INFO:tensorflow:step = 7300, loss = 0.7034655 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.642\n",
      "INFO:tensorflow:step = 7400, loss = 0.88333774 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.807\n",
      "INFO:tensorflow:step = 7500, loss = 0.9783244 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.02\n",
      "INFO:tensorflow:step = 7600, loss = 4.0395284 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.573\n",
      "INFO:tensorflow:step = 7700, loss = 0.56903523 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.737\n",
      "INFO:tensorflow:step = 7800, loss = 0.6339196 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.586\n",
      "INFO:tensorflow:step = 7900, loss = 8.927298 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.279\n",
      "INFO:tensorflow:step = 8000, loss = 0.49131238 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.682\n",
      "INFO:tensorflow:step = 8100, loss = 0.24454984 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.853\n",
      "INFO:tensorflow:step = 8200, loss = 0.23785128 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.252\n",
      "INFO:tensorflow:step = 8300, loss = 2.0868616 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.128\n",
      "INFO:tensorflow:step = 8400, loss = 0.1995242 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.664\n",
      "INFO:tensorflow:step = 8500, loss = 1.0960124 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.028\n",
      "INFO:tensorflow:step = 8600, loss = 1.7936313 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.861\n",
      "INFO:tensorflow:step = 8700, loss = 0.15160534 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.571\n",
      "INFO:tensorflow:step = 8800, loss = 0.8677814 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.157\n",
      "INFO:tensorflow:step = 8900, loss = 0.59463173 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.364\n",
      "INFO:tensorflow:step = 9000, loss = 11.337121 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.884\n",
      "INFO:tensorflow:step = 9100, loss = 0.13692471 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.598\n",
      "INFO:tensorflow:step = 9200, loss = 0.0821157 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.495\n",
      "INFO:tensorflow:step = 9300, loss = 1.6714867 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.785\n",
      "INFO:tensorflow:step = 9400, loss = 0.19852959 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.752\n",
      "INFO:tensorflow:step = 9500, loss = 0.51618004 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.95\n",
      "INFO:tensorflow:step = 9600, loss = 1.0252277 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.033\n",
      "INFO:tensorflow:step = 9700, loss = 0.035539668 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.378\n",
      "INFO:tensorflow:step = 9800, loss = 3.068529 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.425\n",
      "INFO:tensorflow:step = 9900, loss = 2.766829 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.814\n",
      "INFO:tensorflow:step = 10000, loss = 0.15034595 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.411\n",
      "INFO:tensorflow:step = 10100, loss = 0.34667537 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.144\n",
      "INFO:tensorflow:step = 10200, loss = 1.0127223 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.73\n",
      "INFO:tensorflow:step = 10300, loss = 0.5696814 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.949\n",
      "INFO:tensorflow:step = 10400, loss = 0.39141417 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.806\n",
      "INFO:tensorflow:step = 10500, loss = 0.88926494 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.811\n",
      "INFO:tensorflow:step = 10600, loss = 0.28633472 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.569\n",
      "INFO:tensorflow:step = 10700, loss = 0.3609546 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.328\n",
      "INFO:tensorflow:step = 10800, loss = 0.23311268 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.194\n",
      "INFO:tensorflow:step = 10900, loss = 0.46534473 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.692\n",
      "INFO:tensorflow:step = 11000, loss = 0.2788514 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.327\n",
      "INFO:tensorflow:step = 11100, loss = 0.14308032 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.657\n",
      "INFO:tensorflow:step = 11200, loss = 0.46474054 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.452\n",
      "INFO:tensorflow:step = 11300, loss = 0.065608695 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.091\n",
      "INFO:tensorflow:step = 11400, loss = 0.72807753 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.564\n",
      "INFO:tensorflow:step = 11500, loss = 0.13934019 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.081\n",
      "INFO:tensorflow:step = 11600, loss = 0.3908527 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.373\n",
      "INFO:tensorflow:step = 11700, loss = 0.88925004 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.764\n",
      "INFO:tensorflow:step = 11800, loss = 0.71312666 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.187\n",
      "INFO:tensorflow:step = 11900, loss = 0.07139435 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.857\n",
      "INFO:tensorflow:step = 12000, loss = 0.08925169 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.634\n",
      "INFO:tensorflow:step = 12100, loss = 1.0574396 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.987\n",
      "INFO:tensorflow:step = 12200, loss = 0.37355533 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.345\n",
      "INFO:tensorflow:step = 12300, loss = 0.2948486 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.971\n",
      "INFO:tensorflow:step = 12400, loss = 0.38047278 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.011\n",
      "INFO:tensorflow:step = 12500, loss = 0.35432005 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.984\n",
      "INFO:tensorflow:step = 12600, loss = 0.49040693 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.734\n",
      "INFO:tensorflow:step = 12700, loss = 0.31863955 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.145\n",
      "INFO:tensorflow:step = 12800, loss = 0.30658108 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.99\n",
      "INFO:tensorflow:step = 12900, loss = 2.537376 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.907\n",
      "INFO:tensorflow:step = 13000, loss = 0.48227823 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.425\n",
      "INFO:tensorflow:step = 13100, loss = 0.98691297 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.992\n",
      "INFO:tensorflow:step = 13200, loss = 1.1292936 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.074\n",
      "INFO:tensorflow:step = 13300, loss = 0.54439676 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.423\n",
      "INFO:tensorflow:step = 13400, loss = 0.77024406 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.003\n",
      "INFO:tensorflow:step = 13500, loss = 0.29333743 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.899\n",
      "INFO:tensorflow:step = 13600, loss = 0.14708489 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.815\n",
      "INFO:tensorflow:step = 13700, loss = 0.039672777 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.373\n",
      "INFO:tensorflow:step = 13800, loss = 0.104692414 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.494\n",
      "INFO:tensorflow:step = 13900, loss = 0.042336054 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.288\n",
      "INFO:tensorflow:step = 14000, loss = 0.09516668 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.219\n",
      "INFO:tensorflow:step = 14100, loss = 0.3234803 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.104\n",
      "INFO:tensorflow:step = 14200, loss = 0.9829224 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.243\n",
      "INFO:tensorflow:step = 14300, loss = 0.03908633 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.441\n",
      "INFO:tensorflow:step = 14400, loss = 0.2936728 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.528\n",
      "INFO:tensorflow:step = 14500, loss = 0.0929689 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.73\n",
      "INFO:tensorflow:step = 14600, loss = 0.4099194 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.536\n",
      "INFO:tensorflow:step = 14700, loss = 0.3032488 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.395\n",
      "INFO:tensorflow:step = 14800, loss = 0.022811612 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.379\n",
      "INFO:tensorflow:step = 14900, loss = 1.2435706 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.686\n",
      "INFO:tensorflow:step = 15000, loss = 0.06520685 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.04\n",
      "INFO:tensorflow:step = 15100, loss = 0.15437809 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.482\n",
      "INFO:tensorflow:step = 15200, loss = 0.14846396 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.63\n",
      "INFO:tensorflow:step = 15300, loss = 0.15027153 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.208\n",
      "INFO:tensorflow:step = 15400, loss = 0.42936242 (0.386 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 262.701\n",
      "INFO:tensorflow:step = 15500, loss = 0.08749858 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.29\n",
      "INFO:tensorflow:step = 15600, loss = 0.0065476447 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.007\n",
      "INFO:tensorflow:step = 15700, loss = 0.1333478 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.052\n",
      "INFO:tensorflow:step = 15800, loss = 0.7242329 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.126\n",
      "INFO:tensorflow:step = 15900, loss = 0.48061615 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.818\n",
      "INFO:tensorflow:step = 16000, loss = 0.11208325 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.645\n",
      "INFO:tensorflow:step = 16100, loss = 0.052744657 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.163\n",
      "INFO:tensorflow:step = 16200, loss = 0.05338367 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.011\n",
      "INFO:tensorflow:step = 16300, loss = 0.17958169 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.958\n",
      "INFO:tensorflow:step = 16400, loss = 0.08147025 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.04\n",
      "INFO:tensorflow:step = 16500, loss = 0.47050148 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.443\n",
      "INFO:tensorflow:step = 16600, loss = 0.7583815 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.251\n",
      "INFO:tensorflow:step = 16700, loss = 0.12195743 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.346\n",
      "INFO:tensorflow:step = 16800, loss = 0.24714163 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.075\n",
      "INFO:tensorflow:step = 16900, loss = 0.07129266 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.29\n",
      "INFO:tensorflow:step = 17000, loss = 0.24067208 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.562\n",
      "INFO:tensorflow:step = 17100, loss = 0.45677984 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.527\n",
      "INFO:tensorflow:step = 17200, loss = 0.50007296 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.335\n",
      "INFO:tensorflow:step = 17300, loss = 0.14639086 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.979\n",
      "INFO:tensorflow:step = 17400, loss = 0.18119174 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.05\n",
      "INFO:tensorflow:step = 17500, loss = 0.36425027 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.292\n",
      "INFO:tensorflow:step = 17600, loss = 0.16035822 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.628\n",
      "INFO:tensorflow:step = 17700, loss = 0.024875596 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.731\n",
      "INFO:tensorflow:step = 17800, loss = 0.031474687 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.087\n",
      "INFO:tensorflow:step = 17900, loss = 0.23477547 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.44\n",
      "INFO:tensorflow:step = 18000, loss = 0.07580711 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.587\n",
      "INFO:tensorflow:step = 18100, loss = 0.19453827 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.539\n",
      "INFO:tensorflow:step = 18200, loss = 0.18246664 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.536\n",
      "INFO:tensorflow:step = 18300, loss = 0.08312911 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.348\n",
      "INFO:tensorflow:step = 18400, loss = 0.10684702 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.798\n",
      "INFO:tensorflow:step = 18500, loss = 0.14239007 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.171\n",
      "INFO:tensorflow:step = 18600, loss = 0.003632055 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.818\n",
      "INFO:tensorflow:step = 18700, loss = 0.59302324 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.318\n",
      "INFO:tensorflow:step = 18800, loss = 0.058321584 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.974\n",
      "INFO:tensorflow:step = 18900, loss = 0.0312019 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.478\n",
      "INFO:tensorflow:step = 19000, loss = 0.038949154 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.671\n",
      "INFO:tensorflow:step = 19100, loss = 0.13634291 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.816\n",
      "INFO:tensorflow:step = 19200, loss = 0.25858966 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.668\n",
      "INFO:tensorflow:step = 19300, loss = 0.30716437 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.863\n",
      "INFO:tensorflow:step = 19400, loss = 0.026662283 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.509\n",
      "INFO:tensorflow:step = 19500, loss = 0.115941904 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.144\n",
      "INFO:tensorflow:step = 19600, loss = 0.14237006 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.814\n",
      "INFO:tensorflow:step = 19700, loss = 0.11658988 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.966\n",
      "INFO:tensorflow:step = 19800, loss = 0.15307045 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.654\n",
      "INFO:tensorflow:step = 19900, loss = 0.015999887 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.083\n",
      "INFO:tensorflow:step = 20000, loss = 0.123146 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.112\n",
      "INFO:tensorflow:step = 20100, loss = 0.021915428 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.622\n",
      "INFO:tensorflow:step = 20200, loss = 0.06086047 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.263\n",
      "INFO:tensorflow:step = 20300, loss = 0.033355236 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.502\n",
      "INFO:tensorflow:step = 20400, loss = 0.14529747 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.981\n",
      "INFO:tensorflow:step = 20500, loss = 0.22265784 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.216\n",
      "INFO:tensorflow:step = 20600, loss = 0.04306725 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.862\n",
      "INFO:tensorflow:step = 20700, loss = 0.109329335 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.322\n",
      "INFO:tensorflow:step = 20800, loss = 0.106583804 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.341\n",
      "INFO:tensorflow:step = 20900, loss = 0.15186071 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.96\n",
      "INFO:tensorflow:step = 21000, loss = 0.0146353245 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.456\n",
      "INFO:tensorflow:step = 21100, loss = 0.82643896 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.985\n",
      "INFO:tensorflow:step = 21200, loss = 0.023322135 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.848\n",
      "INFO:tensorflow:step = 21300, loss = 0.011647667 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.648\n",
      "INFO:tensorflow:step = 21400, loss = 0.0021295517 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.416\n",
      "INFO:tensorflow:step = 21500, loss = 0.1693876 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.221\n",
      "INFO:tensorflow:step = 21600, loss = 0.08487635 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.52\n",
      "INFO:tensorflow:step = 21700, loss = 0.21004048 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.054\n",
      "INFO:tensorflow:step = 21800, loss = 0.2062213 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.596\n",
      "INFO:tensorflow:step = 21900, loss = 0.2273369 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.361\n",
      "INFO:tensorflow:step = 22000, loss = 0.12884364 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.886\n",
      "INFO:tensorflow:step = 22100, loss = 0.04435118 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.226\n",
      "INFO:tensorflow:step = 22200, loss = 0.15572992 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.761\n",
      "INFO:tensorflow:step = 22300, loss = 0.05730725 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.871\n",
      "INFO:tensorflow:step = 22400, loss = 0.074289836 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.27\n",
      "INFO:tensorflow:step = 22500, loss = 0.11658883 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.317\n",
      "INFO:tensorflow:step = 22600, loss = 0.060112778 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.26\n",
      "INFO:tensorflow:step = 22700, loss = 0.13110718 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.072\n",
      "INFO:tensorflow:step = 22800, loss = 0.048155785 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.878\n",
      "INFO:tensorflow:step = 22900, loss = 0.123735875 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.499\n",
      "INFO:tensorflow:step = 23000, loss = 0.064823225 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.614\n",
      "INFO:tensorflow:step = 23100, loss = 0.25143743 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.233\n",
      "INFO:tensorflow:step = 23200, loss = 0.1324618 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.796\n",
      "INFO:tensorflow:step = 23300, loss = 0.013935374 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.366\n",
      "INFO:tensorflow:step = 23400, loss = 0.045195643 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.906\n",
      "INFO:tensorflow:step = 23500, loss = 0.03418775 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 23600, loss = 0.02167936 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.534\n",
      "INFO:tensorflow:step = 23700, loss = 0.06361225 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.094\n",
      "INFO:tensorflow:step = 23800, loss = 0.038734242 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.665\n",
      "INFO:tensorflow:step = 23900, loss = 0.07789026 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.446\n",
      "INFO:tensorflow:step = 24000, loss = 0.093659624 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.35\n",
      "INFO:tensorflow:step = 24100, loss = 0.08302689 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.535\n",
      "INFO:tensorflow:step = 24200, loss = 0.15013893 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.071\n",
      "INFO:tensorflow:step = 24300, loss = 0.09041694 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.966\n",
      "INFO:tensorflow:step = 24400, loss = 0.2220552 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.246\n",
      "INFO:tensorflow:step = 24500, loss = 0.013315113 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.386\n",
      "INFO:tensorflow:step = 24600, loss = 0.08032974 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.74\n",
      "INFO:tensorflow:step = 24700, loss = 0.002821502 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.389\n",
      "INFO:tensorflow:step = 24800, loss = 0.08229752 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.84\n",
      "INFO:tensorflow:step = 24900, loss = 0.020740507 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.659\n",
      "INFO:tensorflow:step = 25000, loss = 0.027606651 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.138\n",
      "INFO:tensorflow:step = 25100, loss = 0.065551676 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.287\n",
      "INFO:tensorflow:step = 25200, loss = 0.0443954 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.064\n",
      "INFO:tensorflow:step = 25300, loss = 0.30363366 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.855\n",
      "INFO:tensorflow:step = 25400, loss = 0.058687948 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.016\n",
      "INFO:tensorflow:step = 25500, loss = 0.20759715 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.541\n",
      "INFO:tensorflow:step = 25600, loss = 0.1513436 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.629\n",
      "INFO:tensorflow:step = 25700, loss = 0.05560633 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.837\n",
      "INFO:tensorflow:step = 25800, loss = 0.07510159 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.715\n",
      "INFO:tensorflow:step = 25900, loss = 0.030897435 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.654\n",
      "INFO:tensorflow:step = 26000, loss = 0.006158662 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.846\n",
      "INFO:tensorflow:step = 26100, loss = 0.04196529 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.031\n",
      "INFO:tensorflow:step = 26200, loss = 0.18041065 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.007\n",
      "INFO:tensorflow:step = 26300, loss = 0.048447594 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.749\n",
      "INFO:tensorflow:step = 26400, loss = 0.04509505 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.336\n",
      "INFO:tensorflow:step = 26500, loss = 0.0068659484 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.628\n",
      "INFO:tensorflow:step = 26600, loss = 0.018599799 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.605\n",
      "INFO:tensorflow:step = 26700, loss = 0.03884049 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.5\n",
      "INFO:tensorflow:step = 26800, loss = 0.11208301 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.265\n",
      "INFO:tensorflow:step = 26900, loss = 0.046894215 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.876\n",
      "INFO:tensorflow:step = 27000, loss = 0.09725279 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.001\n",
      "INFO:tensorflow:step = 27100, loss = 0.103848994 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.147\n",
      "INFO:tensorflow:step = 27200, loss = 0.051144443 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.51\n",
      "INFO:tensorflow:step = 27300, loss = 0.011204765 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.49\n",
      "INFO:tensorflow:step = 27400, loss = 0.16699763 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.043\n",
      "INFO:tensorflow:step = 27500, loss = 0.07180181 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.878\n",
      "INFO:tensorflow:step = 27600, loss = 0.017681142 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.677\n",
      "INFO:tensorflow:step = 27700, loss = 0.00081385445 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.515\n",
      "INFO:tensorflow:step = 27800, loss = 0.029356413 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.173\n",
      "INFO:tensorflow:step = 27900, loss = 0.058919683 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.397\n",
      "INFO:tensorflow:step = 28000, loss = 0.1157862 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.312\n",
      "INFO:tensorflow:step = 28100, loss = 0.043232664 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.742\n",
      "INFO:tensorflow:step = 28200, loss = 0.004034336 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.942\n",
      "INFO:tensorflow:step = 28300, loss = 0.09170307 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.204\n",
      "INFO:tensorflow:step = 28400, loss = 0.013191117 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.469\n",
      "INFO:tensorflow:step = 28500, loss = 0.046186753 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.443\n",
      "INFO:tensorflow:step = 28600, loss = 0.06668156 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.98\n",
      "INFO:tensorflow:step = 28700, loss = 0.012081092 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.772\n",
      "INFO:tensorflow:step = 28800, loss = 0.092202686 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.345\n",
      "INFO:tensorflow:step = 28900, loss = 0.020219464 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.058\n",
      "INFO:tensorflow:step = 29000, loss = 0.06553914 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.863\n",
      "INFO:tensorflow:step = 29100, loss = 0.05519265 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.995\n",
      "INFO:tensorflow:step = 29200, loss = 0.011095663 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.52\n",
      "INFO:tensorflow:step = 29300, loss = 0.01547205 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.239\n",
      "INFO:tensorflow:step = 29400, loss = 0.027092982 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.753\n",
      "INFO:tensorflow:step = 29500, loss = 0.055773653 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.233\n",
      "INFO:tensorflow:step = 29600, loss = 0.0014234276 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.786\n",
      "INFO:tensorflow:step = 29700, loss = 0.08518766 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.921\n",
      "INFO:tensorflow:step = 29800, loss = 0.015841357 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.795\n",
      "INFO:tensorflow:step = 29900, loss = 0.101528436 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.491\n",
      "INFO:tensorflow:step = 30000, loss = 0.07036758 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.377\n",
      "INFO:tensorflow:step = 30100, loss = 0.060425967 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.012\n",
      "INFO:tensorflow:step = 30200, loss = 0.02172098 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.1\n",
      "INFO:tensorflow:step = 30300, loss = 0.032799672 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.159\n",
      "INFO:tensorflow:step = 30400, loss = 0.014343017 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.005\n",
      "INFO:tensorflow:step = 30500, loss = 0.010806112 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.616\n",
      "INFO:tensorflow:step = 30600, loss = 0.10679674 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.409\n",
      "INFO:tensorflow:step = 30700, loss = 0.03692382 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.116\n",
      "INFO:tensorflow:step = 30800, loss = 0.032425925 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.418\n",
      "INFO:tensorflow:step = 30900, loss = 0.050024554 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.216\n",
      "INFO:tensorflow:step = 31000, loss = 0.07834155 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.093\n",
      "INFO:tensorflow:step = 31100, loss = 0.07127885 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.615\n",
      "INFO:tensorflow:step = 31200, loss = 0.18465567 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.302\n",
      "INFO:tensorflow:step = 31300, loss = 0.02863951 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.961\n",
      "INFO:tensorflow:step = 31400, loss = 0.09708157 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.488\n",
      "INFO:tensorflow:step = 31500, loss = 0.0028697993 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.513\n",
      "INFO:tensorflow:step = 31600, loss = 0.016383495 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 31700, loss = 0.111991316 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.873\n",
      "INFO:tensorflow:step = 31800, loss = 0.050403416 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.865\n",
      "INFO:tensorflow:step = 31900, loss = 0.032373898 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.979\n",
      "INFO:tensorflow:step = 32000, loss = 0.03886242 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.683\n",
      "INFO:tensorflow:step = 32100, loss = 0.03413992 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.041\n",
      "INFO:tensorflow:step = 32200, loss = 0.016202237 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.163\n",
      "INFO:tensorflow:step = 32300, loss = 0.010478177 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.839\n",
      "INFO:tensorflow:step = 32400, loss = 0.16943362 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.802\n",
      "INFO:tensorflow:step = 32500, loss = 0.03847225 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.413\n",
      "INFO:tensorflow:step = 32600, loss = 0.029847013 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.424\n",
      "INFO:tensorflow:step = 32700, loss = 0.034760658 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.441\n",
      "INFO:tensorflow:step = 32800, loss = 0.04447126 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.792\n",
      "INFO:tensorflow:step = 32900, loss = 0.04525877 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.261\n",
      "INFO:tensorflow:step = 33000, loss = 0.12667896 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.269\n",
      "INFO:tensorflow:step = 33100, loss = 0.01181178 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.69\n",
      "INFO:tensorflow:step = 33200, loss = 0.031310037 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.5\n",
      "INFO:tensorflow:step = 33300, loss = 0.031336136 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.14\n",
      "INFO:tensorflow:step = 33400, loss = 0.024642093 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.002\n",
      "INFO:tensorflow:step = 33500, loss = 0.077561006 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.257\n",
      "INFO:tensorflow:step = 33600, loss = 0.002097213 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.73\n",
      "INFO:tensorflow:step = 33700, loss = 0.002314605 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.678\n",
      "INFO:tensorflow:step = 33800, loss = 0.026413275 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.43\n",
      "INFO:tensorflow:step = 33900, loss = 0.006829413 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.426\n",
      "INFO:tensorflow:step = 34000, loss = 0.037457 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.652\n",
      "INFO:tensorflow:step = 34100, loss = 0.05131053 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.142\n",
      "INFO:tensorflow:step = 34200, loss = 0.006042301 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.694\n",
      "INFO:tensorflow:step = 34300, loss = 0.00049718015 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.236\n",
      "INFO:tensorflow:step = 34400, loss = 0.0061136624 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.39\n",
      "INFO:tensorflow:step = 34500, loss = 0.012863025 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.259\n",
      "INFO:tensorflow:step = 34600, loss = 0.07141531 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.667\n",
      "INFO:tensorflow:step = 34700, loss = 0.019533385 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.489\n",
      "INFO:tensorflow:step = 34800, loss = 0.049051665 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.734\n",
      "INFO:tensorflow:step = 34900, loss = 0.039976988 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.717\n",
      "INFO:tensorflow:step = 35000, loss = 0.04248359 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.767\n",
      "INFO:tensorflow:step = 35100, loss = 0.026967663 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.148\n",
      "INFO:tensorflow:step = 35200, loss = 0.074301854 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.969\n",
      "INFO:tensorflow:step = 35300, loss = 0.011366382 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.265\n",
      "INFO:tensorflow:step = 35400, loss = 0.011627253 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.879\n",
      "INFO:tensorflow:step = 35500, loss = 0.024143334 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.663\n",
      "INFO:tensorflow:step = 35600, loss = 0.011681138 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.816\n",
      "INFO:tensorflow:step = 35700, loss = 0.010944793 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.973\n",
      "INFO:tensorflow:step = 35800, loss = 0.0010104753 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.19\n",
      "INFO:tensorflow:step = 35900, loss = 0.025335383 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.116\n",
      "INFO:tensorflow:step = 36000, loss = 0.021533959 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.781\n",
      "INFO:tensorflow:step = 36100, loss = 0.071630426 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.135\n",
      "INFO:tensorflow:step = 36200, loss = 0.006626383 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.408\n",
      "INFO:tensorflow:step = 36300, loss = 0.011144869 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.586\n",
      "INFO:tensorflow:step = 36400, loss = 0.008421948 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.339\n",
      "INFO:tensorflow:step = 36500, loss = 0.044640433 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.737\n",
      "INFO:tensorflow:step = 36600, loss = 0.06931773 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.849\n",
      "INFO:tensorflow:step = 36700, loss = 0.05114981 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.185\n",
      "INFO:tensorflow:step = 36800, loss = 0.019616049 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.249\n",
      "INFO:tensorflow:step = 36900, loss = 0.08334398 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.248\n",
      "INFO:tensorflow:step = 37000, loss = 0.050887287 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.327\n",
      "INFO:tensorflow:step = 37100, loss = 0.016587973 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.883\n",
      "INFO:tensorflow:step = 37200, loss = 0.021949591 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.992\n",
      "INFO:tensorflow:step = 37300, loss = 0.03517453 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.339\n",
      "INFO:tensorflow:step = 37400, loss = 0.030739177 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.177\n",
      "INFO:tensorflow:step = 37500, loss = 0.026877217 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.093\n",
      "INFO:tensorflow:step = 37600, loss = 0.009317229 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.4\n",
      "INFO:tensorflow:step = 37700, loss = 0.001852287 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.589\n",
      "INFO:tensorflow:step = 37800, loss = 0.058886893 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.489\n",
      "INFO:tensorflow:step = 37900, loss = 0.036007952 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.228\n",
      "INFO:tensorflow:step = 38000, loss = 0.006974466 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.782\n",
      "INFO:tensorflow:step = 38100, loss = 0.008789726 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.963\n",
      "INFO:tensorflow:step = 38200, loss = 0.026784591 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.009\n",
      "INFO:tensorflow:step = 38300, loss = 0.086854324 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.122\n",
      "INFO:tensorflow:step = 38400, loss = 0.06177672 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.647\n",
      "INFO:tensorflow:step = 38500, loss = 0.01618424 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.66\n",
      "INFO:tensorflow:step = 38600, loss = 0.0019801082 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.402\n",
      "INFO:tensorflow:step = 38700, loss = 0.011166852 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.54\n",
      "INFO:tensorflow:step = 38800, loss = 0.025173362 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.121\n",
      "INFO:tensorflow:step = 38900, loss = 0.0030598745 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.964\n",
      "INFO:tensorflow:step = 39000, loss = 0.10698363 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.988\n",
      "INFO:tensorflow:step = 39100, loss = 0.042556103 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.036\n",
      "INFO:tensorflow:step = 39200, loss = 0.0085095 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.533\n",
      "INFO:tensorflow:step = 39300, loss = 0.002220306 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.138\n",
      "INFO:tensorflow:step = 39400, loss = 0.022645373 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.544\n",
      "INFO:tensorflow:step = 39500, loss = 0.01051457 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.645\n",
      "INFO:tensorflow:step = 39600, loss = 0.024810001 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.617\n",
      "INFO:tensorflow:step = 39700, loss = 0.03190752 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 39800, loss = 0.034308024 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.862\n",
      "INFO:tensorflow:step = 39900, loss = 0.00018286196 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.054\n",
      "INFO:tensorflow:step = 40000, loss = 0.033133756 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.261\n",
      "INFO:tensorflow:step = 40100, loss = 0.001787411 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.168\n",
      "INFO:tensorflow:step = 40200, loss = 0.012341288 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.017\n",
      "INFO:tensorflow:step = 40300, loss = 0.012403387 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.606\n",
      "INFO:tensorflow:step = 40400, loss = 0.0034967377 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.282\n",
      "INFO:tensorflow:step = 40500, loss = 0.04176349 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.361\n",
      "INFO:tensorflow:step = 40600, loss = 0.007430765 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.328\n",
      "INFO:tensorflow:step = 40700, loss = 0.0127245225 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.081\n",
      "INFO:tensorflow:step = 40800, loss = 0.004241822 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.619\n",
      "INFO:tensorflow:step = 40900, loss = 0.013507329 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.869\n",
      "INFO:tensorflow:step = 41000, loss = 0.03674578 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.112\n",
      "INFO:tensorflow:step = 41100, loss = 0.035179816 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.571\n",
      "INFO:tensorflow:step = 41200, loss = 0.0044973367 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.768\n",
      "INFO:tensorflow:step = 41300, loss = 0.057832964 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.425\n",
      "INFO:tensorflow:step = 41400, loss = 0.025011282 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.718\n",
      "INFO:tensorflow:step = 41500, loss = 0.0038611824 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.709\n",
      "INFO:tensorflow:step = 41600, loss = 0.07049715 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.402\n",
      "INFO:tensorflow:step = 41700, loss = 0.027952716 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.776\n",
      "INFO:tensorflow:step = 41800, loss = 0.06886788 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.41\n",
      "INFO:tensorflow:step = 41900, loss = 0.0024687592 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.464\n",
      "INFO:tensorflow:step = 42000, loss = 0.0018562647 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.194\n",
      "INFO:tensorflow:step = 42100, loss = 0.022080686 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.621\n",
      "INFO:tensorflow:step = 42200, loss = 0.03665806 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.066\n",
      "INFO:tensorflow:step = 42300, loss = 0.0036223165 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.115\n",
      "INFO:tensorflow:step = 42400, loss = 0.0131826475 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.159\n",
      "INFO:tensorflow:step = 42500, loss = 0.014420848 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.985\n",
      "INFO:tensorflow:step = 42600, loss = 0.002409441 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.832\n",
      "INFO:tensorflow:step = 42700, loss = 0.021977747 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.014\n",
      "INFO:tensorflow:step = 42800, loss = 0.008078122 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.176\n",
      "INFO:tensorflow:step = 42900, loss = 0.030350532 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.927\n",
      "INFO:tensorflow:step = 43000, loss = 0.008168449 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.188\n",
      "INFO:tensorflow:step = 43100, loss = 0.0104102455 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.482\n",
      "INFO:tensorflow:step = 43200, loss = 0.0050620157 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.112\n",
      "INFO:tensorflow:step = 43300, loss = 0.0058955164 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.575\n",
      "INFO:tensorflow:step = 43400, loss = 0.0038092812 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.259\n",
      "INFO:tensorflow:step = 43500, loss = 0.015698273 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.92\n",
      "INFO:tensorflow:step = 43600, loss = 0.018452778 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.519\n",
      "INFO:tensorflow:step = 43700, loss = 0.013629042 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.321\n",
      "INFO:tensorflow:step = 43800, loss = 0.009193347 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.698\n",
      "INFO:tensorflow:step = 43900, loss = 0.029771423 (0.305 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 44000 into /tmp/tmpj1_i_7bd/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.01705248.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7fd8e00b67b8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "dnn_clf = tf.estimator.DNNClassifier(hidden_units=[300,100], n_classes=10,\n",
    "                                     feature_columns=feature_cols)\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, num_epochs=40, batch_size=50, shuffle=True)\n",
    "dnn_clf.train(input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-12-15:25:47\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpj1_i_7bd/model.ckpt-44000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-12-15:25:48\n",
      "INFO:tensorflow:Saving dict for global step 44000: accuracy = 0.9784, average_loss = 0.11250929, global_step = 44000, loss = 14.241682\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test}, y=y_test, shuffle=False)\n",
    "eval_results = dnn_clf.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9784,\n",
       " 'average_loss': 0.11250929,\n",
       " 'global_step': 44000,\n",
       " 'loss': 14.241682}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpj1_i_7bd/model.ckpt-44000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([7]),\n",
       " 'classes': array([b'7'], dtype=object),\n",
       " 'logits': array([-11.688817  ,  -8.078765  ,  -4.9356127 ,   2.606026  ,\n",
       "        -12.357452  , -14.665477  , -19.108204  ,  18.850456  ,\n",
       "         -5.2496376 ,  -0.21223307], dtype=float32),\n",
       " 'probabilities': array([5.4571077e-14, 2.0173785e-12, 4.6756488e-11, 8.8131955e-08,\n",
       "        2.7962592e-14, 2.7810878e-15, 3.2716234e-17, 9.9999988e-01,\n",
       "        3.4155623e-11, 5.2623457e-09], dtype=float32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_iter = dnn_clf.predict(input_fn=test_input_fn)\n",
    "y_pred = list(y_pred_iter)\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DNNClassifier` class creates all the neuron layers, based on the ReLU activation function (change `activation_fn` hyperparameter). The output layer relies on the softmax function, and the cost function is cross entropy.\n",
    "\n",
    "### Training a DNN Using Plain TensorFlow\n",
    "\n",
    "Mini-batch Gradient Descent to train it on the MNIST dataset. 1st step - construction phase, building the TensorFlow graph. 2nd step - the execution phase, where you actually run the graph to train the model.\n",
    "\n",
    "#### Construction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)    # helps the algorithm converge much faster\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")\n",
    "    y_proba = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `logits` is the output of the neural network _before_ going through the `softmax` activation function: for optimization reasons, we will handle the softmax computation later.\n",
    "\n",
    "You can use TensorFlow's `tf.layers.dense()` function to create a fully connected layer. methods: `name`, `activation`, `kernel_initializer`, the default `activation` is now `None`.\n",
    "\n",
    "The `sparse_softmax_cross_entropy_with_logits()` function is equivalent to applying the softmax activation function and then computing the cross entropy, but it is more efficient, and it properly takes care of corner cases like logits equal to 0. There is also another function called `softmax_cross_entropy_with_logits()`, which takes labels in the form of one-hot vectors.\n",
    "\n",
    "#### Execution Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "0 Train accuracy: 0.98 Test accuracy: 0.9131\n",
      "1 Train accuracy: 0.96 Test accuracy: 0.929\n",
      "2 Train accuracy: 0.9 Test accuracy: 0.9371\n",
      "3 Train accuracy: 0.98 Test accuracy: 0.943\n",
      "4 Train accuracy: 0.96 Test accuracy: 0.9482\n",
      "5 Train accuracy: 0.98 Test accuracy: 0.9506\n",
      "6 Train accuracy: 0.94 Test accuracy: 0.9547\n",
      "7 Train accuracy: 1.0 Test accuracy: 0.958\n",
      "8 Train accuracy: 0.94 Test accuracy: 0.9586\n",
      "9 Train accuracy: 0.98 Test accuracy: 0.9616\n",
      "10 Train accuracy: 1.0 Test accuracy: 0.9628\n",
      "11 Train accuracy: 0.96 Test accuracy: 0.9643\n",
      "12 Train accuracy: 1.0 Test accuracy: 0.9663\n",
      "13 Train accuracy: 0.96 Test accuracy: 0.967\n",
      "14 Train accuracy: 0.94 Test accuracy: 0.9667\n",
      "15 Train accuracy: 0.98 Test accuracy: 0.9681\n",
      "16 Train accuracy: 0.98 Test accuracy: 0.9693\n",
      "17 Train accuracy: 1.0 Test accuracy: 0.9703\n",
      "18 Train accuracy: 0.98 Test accuracy: 0.9697\n",
      "19 Train accuracy: 1.0 Test accuracy: 0.9706\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                        y: mnist.test.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./logs/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Neural Network\n",
    "\n",
    "First the code loads the model parameters from disk. Then it loads some new images that you want to classify. Remember to apply the same feature scaling as for the training data (in this case, scale it from 0 to 1). Then the code evaluates the `logits` node. If you wanted to know all the estimated class probabilities, you would need to apply the `softmax()` function to the logits, but if you just want to predict a class, you can simply pick the class that has the highest logit value (using the `argmax()` function does the trick)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./logs/my_model_final.ckpt\")\n",
    "    X_new_scaled = [...] # some new images (scaled from 0 to 1)\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning Neural Network Hyperparameters\n",
    "\n",
    "The flexibility of neural networks is also one of their main drawbacks: there are many hyperparameters to tweak. Any _network topology_, number of layers, number of neurons per layer, type of activation function, weight initialization logic. \n",
    "\n",
    "It is much better to use randomized search over grid search. Another option is to use a tool such as Oscar (http://oscar.calldesk.ai/), which implements more complex algorithms to help you find a good set of hyperparameters quickly.\n",
    "\n",
    "#### Number of Hidden Layers\n",
    "\n",
    "MLP with just one hidden layer can model even the most complex functions provided it has enough neurons. However, deep networks have a much higher parameter efficiency than shallow ones: they can model complex functions using exponentially fewer neurons than shallow nets, making them much faster to train.\n",
    "\n",
    "Real-world data is often structured in such a hierarchical way and DNNs automatically take advantage of this fact.\n",
    "\n",
    "Not only does this hierarchical architecture help DNNs converge faster to a good solution, it also\n",
    "improves their ability to generalize to new datasets. \n",
    "\n",
    "In summary, for many problems you can start with just one or two hidden layers and it will work just fine. For more complex problems, you can gradually ramp up the number of hidden layers, until you start overfitting the training set. Very complex tasks, typically require networks with dozens of layers (or even hundreds, but not fully connected ones), and they need a huge amount of training data. However, you will rarely have to train such networks from scratch: it is much more common to reuse parts of a pretrained state-of-the-art network that performs a similar task. Training will be a lot faster and require much less data.\n",
    "\n",
    "#### Number of Neurons per Hidden Layer\n",
    "\n",
    "As for the hidden layers, a common practice is to size them to form a funnel, with fewer and fewer neurons at each layer - the rationale being that many low-level features can coalesce into far fewer high-level features. However, this practice is not as common now, and you may simply use the same size for all hidden layers. Just like for the number of layers, you can try increasing the number of neurons gradually until the network starts overfitting. In general you will get more bang for the buck by increasing the number of layers than the number of neurons per layer.\n",
    "\n",
    "A simpler approach is to pick a model with more layers and neurons than you actually need, then use _early stopping_ to prevent it from overfitting (and other regularization techniques, especially _dropout_). This has been dubbed the “stretch pants” approach: instead of wasting time looking for pants that perfectly match your size, just use large stretch pants that will shrink down to the right size.\n",
    "\n",
    "#### Activation Functions\n",
    "\n",
    "In most cases you can use the ReLU activation function in the hidden layers (or one of its variants). It is a bit faster to compute than other activation functions, and Gradient Descent does not get stuck as much on plateaus, thanks to the fact that it does not saturate for large input values (as opposed to the logistic function or the hyperbolic tangent function, which saturate at 1).\n",
    "\n",
    "For the output layer, the softmax activation function is generally a good choice for classification tasks (when the classes are mutually exclusive). For regression tasks, you can simply use no activation function at all."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
