{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 9. Up and Running with TensorFlow\n",
    "\n",
    "Basic principle: 1. define a graph of computations to perform; 2. TensorFlow takes that graph and run it efficiently using optimized C++ code.\n",
    "\n",
    "<div style=\"width:400 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig9-1.png\" width=400px alt=\"fig9-1\" style=\"padding-bottom:1.0em;padding-top:2.0em;\"></center>_Figure 9-1. A simple computation graph_</div>\n",
    "\n",
    "Importantly, parallel with multiple CPUs or GPUs, distributed computing.\n",
    "\n",
    "Characteristic: clean design, scalability, flexibility, and great documentation. (flexible, scalable, and production-ready)\n",
    "\n",
    "Highlights:\n",
    " - All types of platforms\n",
    " - API _TF.Learn_ ($tensorflow.contrib.learn$)\n",
    " - _TF-slim_ ($tensorflow.contrib.slim$)\n",
    " - APIs <font color=blue>Keras</font> or <font color=blue>Pretty Tensor</font>\n",
    " - Its main Python API offers much more flexibility (at the cost of higher complexity) to create all sorts of computations\n",
    " - Highly efficient C++ implementations\n",
    " - Advanced optimization nodes to search for the parameters (gradient) that minimize a cost function (_automatic differentiating, autodiff_)\n",
    " - Visualization tool _TensorBoard_\n",
    " - Cloud computing\n",
    " - Great community: https://github.com/jtoy/awesome-tensorflow\n",
    " \n",
    "### Installation\n",
    "\n",
    "Install in a virtual environment\n",
    ">$ pip3 install --upgrade tensorflow\n",
    "\n",
    "Check version\n",
    ">$ python3 -c 'import tensorflow; print(tensorflow.__version__)'\n",
    "\n",
    "### Creating Your First Graph and Running It in a Session\n",
    "\n",
    "1. Creates a computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code does not perform any computation, even any variable initialization. To evaluate this graph, open a TensorFlow _session_ and use it to initialize the variables and evaluate f. A TensorFlow session takes care\n",
    "of placing the operations onto devices such as CPUs and GPUs and running them, and it holds all the variable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat $sess.run()$ all the time is a bit cumbersome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the with block, the session is set as the default session. Calling x.initializer.run() is equivalent to calling tf.get_default_session().run(x.initializer), and similarly f.eval() is equivalent to calling tf.get_default_session().run(f). Moreover, the session is automatically closed at the end of the block.\n",
    "\n",
    "Instead of manually running the initializer for every single variable, you can use the global_variables_initializer() function. Note that it does not actually perform the initialization immediately, but rather creates a node in the graph that will initialize all variables when it is run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() # prepare an init node\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run() # actually initialize all the variables\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside Jupyter or within a Python shell you may prefer to create an $InteractiveSession$. The only\n",
    "difference from a regular $Session$ is that when an $InteractiveSession$ is created it automatically sets itself as the default session, so you don't need a with block (but you do need to close the session manually when you are done with it):\n",
    "\n",
    ">sess = tf.InteractiveSession()}\n",
    "<br>\n",
    ">init.run()\n",
    "<br>\n",
    ">result = f.eval()\n",
    "<br>\n",
    ">print(result)\n",
    "<br>\n",
    ">42\n",
    "<br>\n",
    ">sess.close()\n",
    "\n",
    "A TensorFlow program is typically split into two parts: \n",
    "1. Construction phase: builds a computation graph representing the ML model and the computations required to train it.\n",
    "2. Execution phase: runs a loop that evaluates a training step repeatedly, gradually improving the model parameters.\n",
    "\n",
    "### Managing Graphs\n",
    "\n",
    "Any node you create is automatically added to the default graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing multiple independent graphs, create a new Graph and temporarily making it the default graph inside a $with$ block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> graph = tf.Graph()\n",
    ">>> with graph.as_default():\n",
    "...     x2 = tf.Variable(2)\n",
    "...\n",
    ">>> x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>_TIP_</font>\n",
    ">In Jupyter (or in a Python shell), it is common to run the same commands more than once while you are experimenting. As a result, you may end up with a default graph containing many duplicate nodes. One solution is to restart the Jupyter kernel (or the Python shell), but a more convenient solution is to just reset the default graph by running tf.reset_default_graph().\n",
    "\n",
    "### Lifecycle of a Node Value\n",
    "\n",
    "When evaluating a node, TensorFlow automatically determines the set of nodes that it depends on and it evaluates these nodes first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval()) # 10\n",
    "    print(z.eval()) # 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT: it will <font color=red>NOT</font> reuse the result of the previous evaluation of $w$ and $x$. In short, the preceding code evaluates $w$ and $x$ twice.\n",
    "\n",
    "All node values are dropped between graph runs, except variable values, which are maintained by the session across graph runs. A variable starts its life when its initializer is run, and it ends when the session is closed.\n",
    "\n",
    "If you want to evaluate $y$ and $z$ efficiently, without evaluating w and x twice as in the previous code, you\n",
    "must ask TensorFlow to evaluate both y and z in just one graph run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>_WARNING_</font>\n",
    ">In single-process TensorFlow, multiple sessions do not share any state, even if they reuse the same graph (each session would have its own copy of every variable). In distributed TensorFlow, variable state is stored on the servers, not in the sessions, so multiple sessions can share the same variables.\n",
    "\n",
    "### Linear Regression with TensorFlow\n",
    "\n",
    "TensorFlow operators (_ops_), constant and variables (_source ops_), inputs and outputs are multidimensional arrays (_tensors_).\n",
    "\n",
    "The following code manipulates 2D arrays to perform Linear Regression on the California housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main benefit of this code versus computing the Normal Equation directly using NumPy is that TensorFlow will automatically run this on your GPU card.\n",
    "\n",
    "### Implementing Gradient Descent\n",
    "\n",
    "<font color=red>_WARNING_</font>\n",
    ">When using Gradient Descent, remember that it is important to first normalize the input feature vectors, or else training may be much slower.\n",
    "\n",
    "Gradient Descent requires scaling the feature vectors first. We could do this using TF, but let's just use Scikit-Learn for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000000e+00  6.60969987e-17  5.50808322e-18  6.60969987e-17\n",
      " -1.06030602e-16 -1.10161664e-17  3.44255201e-18 -1.07958431e-15\n",
      " -8.52651283e-15]\n",
      "[ 0.38915536  0.36424355  0.5116157  ... -0.06612179 -0.06360587\n",
      "  0.01359031]\n",
      "0.11111111111111005\n",
      "(20640, 9)\n"
     ]
    }
   ],
   "source": [
    "print(scaled_housing_data_plus_bias.mean(axis=0))\n",
    "print(scaled_housing_data_plus_bias.mean(axis=1))\n",
    "print(scaled_housing_data_plus_bias.mean())\n",
    "print(scaled_housing_data_plus_bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually Computing the Gradients\n",
    "\n",
    "The assign() function creates a node that will assign a new value to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 4.6820836\n",
      "Epoch 100 MSE = 0.7089329\n",
      "Epoch 200 MSE = 0.6406445\n",
      "Epoch 300 MSE = 0.6128869\n",
      "Epoch 400 MSE = 0.5923592\n",
      "Epoch 500 MSE = 0.5768639\n",
      "Epoch 600 MSE = 0.565109\n",
      "Epoch 700 MSE = 0.55614835\n",
      "Epoch 800 MSE = 0.54928374\n",
      "Epoch 900 MSE = 0.54399776\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "# # TF autodiff \n",
    "# gradients = tf.gradients(mse, [theta])[0]\n",
    "\n",
    "# # Gradient Descent optimizer\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "# optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9) # momentum optimizer\n",
    "# training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using autodiff\n",
    "\n",
    "Use _symbolic differentiation_ to automatically compute the partial derivatives, but the resulting code would not necessarily be very efficient.\n",
    "\n",
    "TensorFlow's autodiff feature can automatically and efficiently compute the gradients.\n",
    ">gradients = tf.gradients(mse, [theta])[0]\n",
    "\n",
    "The gradients() function takes an op (in this case mse ), a list of variables (in this case just theta ), and it creates a list of ops (one per variable) to compute the gradients of the op with regards to each variable. So the gradients node will compute the gradient vector of the MSE with regards to theta .\n",
    "\n",
    "#### Using an Optimizer\n",
    "\n",
    "Replace the preceding gradients = ... and training_op = ... lines with the following code\n",
    ">optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "<br>\n",
    ">training_op = optimizer.minimize(mse)\n",
    "\n",
    "Change different type of optimizer\n",
    ">optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "\n",
    "### Feeding Data to the Training Algorithm\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
